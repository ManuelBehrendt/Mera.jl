<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Threading and Performance Optimization in Mera.jl · Mera.jl</title><meta name="title" content="Threading and Performance Optimization in Mera.jl · Mera.jl"/><meta property="og:title" content="Threading and Performance Optimization in Mera.jl · Mera.jl"/><meta property="twitter:title" content="Threading and Performance Optimization in Mera.jl · Mera.jl"/><meta name="description" content="Documentation for Mera.jl."/><meta property="og:description" content="Documentation for Mera.jl."/><meta property="twitter:description" content="Documentation for Mera.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Mera.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../00_multi_FirstSteps/">First Steps</a></li><li><span class="tocitem">1 Data Inspection</span><ul><li><a class="tocitem" href="../../01_hydro_First_Inspection/">Hydro</a></li><li><a class="tocitem" href="../../01_particles_First_Inspection/">Particles</a></li><li><a class="tocitem" href="../../01_clumps_First_Inspection/">Clumps</a></li></ul></li><li><span class="tocitem">2 Load by Selection</span><ul><li><a class="tocitem" href="../../02_hydro_Load_Selections/">Hydro</a></li><li><a class="tocitem" href="../../02_particles_Load_Selections/">Particles</a></li><li><a class="tocitem" href="../../02_clumps_Load_Selections/">Clumps</a></li></ul></li><li><span class="tocitem">3 Get Subregions</span><ul><li><a class="tocitem" href="../../03_hydro_Get_Subregions/03_hydro_Get_Subregions/">Hydro</a></li><li><a class="tocitem" href="../../03_particles_Get_Subregions/03_particles_Get_Subregions/">Particles</a></li><li><a class="tocitem" href="../../03_clumps_Get_Subregions/03_clumps_Get_Subregions/">Clumps</a></li></ul></li><li><a class="tocitem" href="../../04_multi_Basic_Calculations/">4 Basic Calculations</a></li><li><a class="tocitem" href="../../05_multi_Masking_Filtering/05_multi_Masking_Filtering/">5 Mask/Filter/Meta</a></li><li><span class="tocitem">6 Projection</span><ul><li><a class="tocitem" href="../../06_hydro_Projection/06_hydro_Projection/">Hydro</a></li><li><a class="tocitem" href="../../06_particles_Projection/06_particles_Projection/">Particles</a></li></ul></li><li><span class="tocitem">7 MERA-Files</span><ul><li><a class="tocitem" href="../../07_multi_Mera_Files/">Mera-Files</a></li><li><a class="tocitem" href="../../07_1_multi_Mera_Files_Converter/">Converter</a></li></ul></li><li><span class="tocitem">8 Volume Rendering</span><ul><li><a class="tocitem" href="../../paraview_intro/">Intro</a></li><li><a class="tocitem" href="../../08_hydro_VTK_export/">Hydro</a></li><li><a class="tocitem" href="../../08_particles_VTK_export/">Particles</a></li></ul></li><li><a class="tocitem" href="../../Miscellaneous/">9 Miscellaneous</a></li><li><a class="tocitem" href="../../examples/">10 Examples</a></li><li><a class="tocitem" href="../multi-threading_intro/">11 Multi-Threading</a></li><li><span class="tocitem">12 Benchmarks</span><ul><li><a class="tocitem" href="../../benchmarks/IO/IOperformance/">Server IO</a></li><li><a class="tocitem" href="../../benchmarks/RAMSES_reading/ramses_reading/">Parallel RAMSES-Files Reading</a></li><li><a class="tocitem" href="../../benchmarks/JLD2_reading/Mera_files_reading/">Mera-Files Reading</a></li><li><a class="tocitem" href="../../benchmarks/Projection/multi_projections/">Parallel Projections</a></li></ul></li><li><span class="tocitem">13 Reference Guide</span><ul><li><a class="tocitem" href="../../quickreference/Julia_Quick_Reference/">Julia</a></li><li><a class="tocitem" href="../../quickreference/Mera_Quick_Reference/">Mera</a></li></ul></li><li><a class="tocitem" href="../../api/">14 API Documentation</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Threading and Performance Optimization in Mera.jl</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Threading and Performance Optimization in Mera.jl</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ManuelBehrendt/Mera.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ManuelBehrendt/Mera.jl/blob/master/docs/src/multi-threading/multi-threading.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Threading-and-Performance-Optimization-in-Mera.jl"><a class="docs-heading-anchor" href="#Threading-and-Performance-Optimization-in-Mera.jl">Threading and Performance Optimization in Mera.jl</a><a id="Threading-and-Performance-Optimization-in-Mera.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Threading-and-Performance-Optimization-in-Mera.jl" title="Permalink"></a></h1><h2 id="Julia-with-Parallel-Computing"><a class="docs-heading-anchor" href="#Julia-with-Parallel-Computing">Julia with Parallel Computing</a><a id="Julia-with-Parallel-Computing-1"></a><a class="docs-heading-anchor-permalink" href="#Julia-with-Parallel-Computing" title="Permalink"></a></h2><p>Julia was designed from the ground up with <strong>native parallel computing capabilities</strong>. Unlike many languages that retrofit parallelism as an afterthought, <a href="https://www.juliabloggers.com/julias-parallel-processing-2/">Julia&#39;s parallel processing</a> is built into the language core, making it uniquely suited for high-performance scientific computing applications like Mera.jl.</p><h3 id="Julia&#39;s-Native-Parallel-Design-Philosophy"><a class="docs-heading-anchor" href="#Julia&#39;s-Native-Parallel-Design-Philosophy">Julia&#39;s Native Parallel Design Philosophy</a><a id="Julia&#39;s-Native-Parallel-Design-Philosophy-1"></a><a class="docs-heading-anchor-permalink" href="#Julia&#39;s-Native-Parallel-Design-Philosophy" title="Permalink"></a></h3><p>According to the <a href="https://docs.julialang.org/en/v1/manual/parallel-computing/">official Julia documentation</a>, Julia supports four categories of concurrent and parallel programming:</p><ol><li><strong>Asynchronous Tasks</strong>: For I/O and event handling</li><li><strong>Multi-threading</strong>: Multiple tasks sharing memory on one machine </li><li><strong>Distributed Computing</strong>: Multiple processes across machines</li><li><strong>GPU Computing</strong>: Native GPU execution</li></ol><p><strong>Key advantage</strong>: Julia&#39;s multi-threading is <strong>composable</strong> - when one multi-threaded function calls another, Julia automatically schedules all threads globally without oversubscribing resources.</p><h4 id="Multi-threading-(Most-Common)"><a class="docs-heading-anchor" href="#Multi-threading-(Most-Common)">Multi-threading (Most Common)</a><a id="Multi-threading-(Most-Common)-1"></a><a class="docs-heading-anchor-permalink" href="#Multi-threading-(Most-Common)" title="Permalink"></a></h4><pre><code class="language-bash hljs"># Start Julia with 4 threads
julia -t 4</code></pre><pre><code class="language-julia hljs"># Parallel for loop
Threads.@threads for i in 1:1000
    process_data(i)
end

# Spawn individual tasks
task = Threads.@spawn expensive_calculation()
result = fetch(task)</code></pre><pre><code class="language-julia hljs"># New in Julia v1.11
# Wait for any task to complete
tasks = [Threads.@spawn compute(data[i]) for i in 1:10]
completed_task = waitany(tasks)

# Wait for all tasks with failure handling
waitall(tasks; failfast=true, throw=true)

</code></pre><h3 id="Key-Features:"><a class="docs-heading-anchor" href="#Key-Features:">Key Features:</a><a id="Key-Features:-1"></a><a class="docs-heading-anchor-permalink" href="#Key-Features:" title="Permalink"></a></h3><h4 id="Shared-Memory-Between-Threads"><a class="docs-heading-anchor" href="#Shared-Memory-Between-Threads">Shared Memory Between Threads</a><a id="Shared-Memory-Between-Threads-1"></a><a class="docs-heading-anchor-permalink" href="#Shared-Memory-Between-Threads" title="Permalink"></a></h4><p>Julia&#39;s multi-threading <strong>provides the ability to schedule Tasks simultaneously on more than one thread or CPU core, sharing memory</strong>. This shared memory model allows threads to access the same data structures without copying.</p><p><strong>Example:</strong></p><pre><code class="language-julia hljs"># All threads can access and modify the same array
shared_array = zeros(1000)
Threads.@threads for i in 1:1000
    shared_array[i] = Threads.threadid()  # Each thread writes to shared memory
end</code></pre><h4 id="Composable-Threading"><a class="docs-heading-anchor" href="#Composable-Threading">Composable Threading</a><a id="Composable-Threading-1"></a><a class="docs-heading-anchor-permalink" href="#Composable-Threading" title="Permalink"></a></h4><p>When one multi-threaded function calls another multi-threaded function, Julia will schedule all the threads globally on available resources, without oversubscribing.</p><p><strong>Example:</strong></p><pre><code class="language-julia hljs">function parallel_outer()
    Threads.@threads for i in 1:10
        parallel_inner(i)  # This calls another threaded function
    end
end

function parallel_inner(data)
    Threads.@threads for j in 1:5
        process(data, j)  # Julia handles thread scheduling automatically
    end
end</code></pre><h4 id="Two-Thread-Pools:-:default-and-:interactive"><a class="docs-heading-anchor" href="#Two-Thread-Pools:-:default-and-:interactive">Two Thread Pools: :default and :interactive</a><a id="Two-Thread-Pools:-:default-and-:interactive-1"></a><a class="docs-heading-anchor-permalink" href="#Two-Thread-Pools:-:default-and-:interactive" title="Permalink"></a></h4><p>Julia supports <strong>two thread pools</strong>: <code>:default</code> for compute-intensive tasks and <code>:interactive</code> for UI and responsive operations.</p><p><strong>Configuration Examples:</strong></p><pre><code class="language-bash hljs"># Start with 4 default threads and 2 interactive threads
julia --threads 4,2

# Or using environment variable
export JULIA_NUM_THREADS=4,2</code></pre><p><strong>Usage Example:</strong></p><pre><code class="language-julia hljs"># Spawn task in default pool (compute-heavy)
task1 = Threads.@spawn expensive_calculation()

# Spawn task in interactive pool (UI/responsive)
task2 = Threads.@spawn :interactive update_progress_bar()</code></pre><p><strong>Verification:</strong></p><pre><code class="language-julia hljs">julia&gt; nthreads(:default)
4
julia&gt; nthreads(:interactive) 
2
julia&gt; threadpool()  # Check current thread&#39;s pool
:interactive</code></pre><h2 id="Garbage-Collection-(GC)-in-Julia-Quick-Reference"><a class="docs-heading-anchor" href="#Garbage-Collection-(GC)-in-Julia-Quick-Reference">Garbage Collection (GC) in Julia - Quick Reference</a><a id="Garbage-Collection-(GC)-in-Julia-Quick-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Garbage-Collection-(GC)-in-Julia-Quick-Reference" title="Permalink"></a></h2><h3 id="What-is-GC?"><a class="docs-heading-anchor" href="#What-is-GC?">What is GC?</a><a id="What-is-GC?-1"></a><a class="docs-heading-anchor-permalink" href="#What-is-GC?" title="Permalink"></a></h3><p><strong>Garbage Collection</strong> automatically frees memory from objects your program no longer uses. It runs in the background, preventing memory leaks and eliminating manual memory management.</p><h3 id="Why-GC-is-Essential"><a class="docs-heading-anchor" href="#Why-GC-is-Essential">Why GC is Essential</a><a id="Why-GC-is-Essential-1"></a><a class="docs-heading-anchor-permalink" href="#Why-GC-is-Essential" title="Permalink"></a></h3><ul><li><strong>Prevents memory leaks</strong> - no need to manually free memory</li><li><strong>Eliminates memory bugs</strong> - no double-free or use-after-free errors</li><li><strong>Enables high-level programming</strong> - dynamic arrays and flexible data structures</li><li><strong>Supports interactive development</strong> - REPL and exploratory analysis</li></ul><h3 id="How-Julia&#39;s-GC-Works"><a class="docs-heading-anchor" href="#How-Julia&#39;s-GC-Works">How Julia&#39;s GC Works</a><a id="How-Julia&#39;s-GC-Works-1"></a><a class="docs-heading-anchor-permalink" href="#How-Julia&#39;s-GC-Works" title="Permalink"></a></h3><ul><li><strong>Mark-and-sweep</strong>: Identifies unused objects and frees their memory</li><li><strong>Generational</strong>: Focuses on recently allocated objects (more likely to be garbage)</li><li><strong>Automatic</strong>: Runs when memory pressure increases</li></ul><h3 id="Key-v1.10-Improvements"><a class="docs-heading-anchor" href="#Key-v1.10-Improvements">Key v1.10+ Improvements</a><a id="Key-v1.10-Improvements-1"></a><a class="docs-heading-anchor-permalink" href="#Key-v1.10-Improvements" title="Permalink"></a></h3><ul><li><strong>Parallel garbage collection</strong> - uses multiple threads for faster cleanup</li><li><strong>Significant speedup</strong> for multithreaded applications</li><li><strong>Control with <code>--gcthreads=N</code></strong> (default: half your thread count)</li></ul><h3 id="Basic-Usage"><a class="docs-heading-anchor" href="#Basic-Usage">Basic Usage</a><a id="Basic-Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-Usage" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Monitor GC activity
@time expensive_computation()  # Shows GC overhead percentage

# Force garbage collection (if needed)
GC.gc()

# Check GC statistics  
GC.gc_num()</code></pre><h3 id="Best-Practices"><a class="docs-heading-anchor" href="#Best-Practices">Best Practices</a><a id="Best-Practices-1"></a><a class="docs-heading-anchor-permalink" href="#Best-Practices" title="Permalink"></a></h3><ul><li><strong>Preallocate arrays</strong> when possible to reduce GC pressure</li><li><strong>Monitor GC time</strong> with <code>@time</code> to identify bottlenecks</li><li><strong>Use parallel GC</strong> for multithreaded applications</li></ul><p>GC enables Julia&#39;s combination of <strong>high performance with high-level convenience</strong>, automatically managing memory so you can focus on your algorithms rather than memory management details.</p><h4 id="Parallel-Garbage-Collection"><a class="docs-heading-anchor" href="#Parallel-Garbage-Collection">Parallel Garbage Collection</a><a id="Parallel-Garbage-Collection-1"></a><a class="docs-heading-anchor-permalink" href="#Parallel-Garbage-Collection" title="Permalink"></a></h4><p>Julia 1.10 introduces parallel garbage collection, which results in significant speedups on garbage collection time for multithreaded allocation-heavy workloads. The system <strong>parallelized the mark phase of the garbage collector (GC)</strong> and **performs marking in parallel.</p><h3 id="–gcthreads-Control"><a class="docs-heading-anchor" href="#–gcthreads-Control">✅ –gcthreads Control</a><a id="–gcthreads-Control-1"></a><a class="docs-heading-anchor-permalink" href="#–gcthreads-Control" title="Permalink"></a></h3><p>You can control GC threads using the <code>--gcthreads</code> command line option.</p><p><strong>Example:</strong></p><pre><code class="language-bash hljs"># Use 4 GC threads
julia --gcthreads=4

# For concurrent sweeping (advanced usage)
julia --gcthreads=4,1</code></pre><p><strong>The default number of garbage collection threads is set to half of the number of compute threads</strong>:</p><p><strong>Example:</strong></p><ul><li>If you start Julia with 8 threads: <code>julia -t 8</code></li><li>Default GC threads = 4 (half of 8)</li><li>You can verify this affects <strong>multithreaded allocation-heavy workloads</strong> significantly</li></ul><h3 id="Practical-Impact"><a class="docs-heading-anchor" href="#Practical-Impact">Practical Impact</a><a id="Practical-Impact-1"></a><a class="docs-heading-anchor-permalink" href="#Practical-Impact" title="Permalink"></a></h3><p>These features deliver substantial performance improvements:</p><ul><li><strong>Significant speedups</strong> on garbage collection time for multithreaded workloads</li><li><strong>Better scaling</strong> with composable threading</li><li><strong>Improved responsiveness</strong> with separate interactive thread pool</li><li><strong>Efficient memory usage</strong> through shared memory model</li></ul><h2 id="Single-file-reading-baseline-performance"><a class="docs-heading-anchor" href="#Single-file-reading-baseline-performance">Single file reading - baseline performance</a><a id="Single-file-reading-baseline-performance-1"></a><a class="docs-heading-anchor-permalink" href="#Single-file-reading-baseline-performance" title="Permalink"></a></h2><h3 id="Understanding-File-I/O-Bottlenecks"><a class="docs-heading-anchor" href="#Understanding-File-I/O-Bottlenecks">Understanding File I/O Bottlenecks</a><a id="Understanding-File-I/O-Bottlenecks-1"></a><a class="docs-heading-anchor-permalink" href="#Understanding-File-I/O-Bottlenecks" title="Permalink"></a></h3><p>Before diving into solutions, let&#39;s understand why reading data can be slow and how parallelism helps.</p><p><strong>Bottlenecks</strong>:</p><ul><li>Storage System Limitations : seek time dominates when accessing many small portions </li><li>File System Metadata Bottlenecks:</li></ul><p>Directory traversal and inode lookups  File permission checks and metadata caching  Lock contention in filesystem metadata structures</p><ul><li>system call overhead</li></ul><p>open,read,close system cals per file</p><ul><li><strong>Storage bandwidth</strong>: Limited by disk read speed</li><li><strong>Memory allocation</strong>: Large arrays require significant memory</li><li><strong>Sequential processing</strong>: CPU waits for I/O operations</li></ul><h3 id="The-Threading-Opportunity"><a class="docs-heading-anchor" href="#The-Threading-Opportunity">The Threading Opportunity</a><a id="The-Threading-Opportunity-1"></a><a class="docs-heading-anchor-permalink" href="#The-Threading-Opportunity" title="Permalink"></a></h3><p>Even single-file reading can benefit from threading through:</p><ul><li><strong>Overlapped I/O</strong>: Reading while processing previous chunks</li><li><strong>Parallel decompression</strong>: Multiple threads decompressing data</li><li><strong>Memory management</strong>: Background garbage collection</li></ul><h2 id="From-Single-Files-to-Many-Files:-The-RAMSES-Challenge"><a class="docs-heading-anchor" href="#From-Single-Files-to-Many-Files:-The-RAMSES-Challenge">From Single Files to Many Files: The RAMSES Challenge</a><a id="From-Single-Files-to-Many-Files:-The-RAMSES-Challenge-1"></a><a class="docs-heading-anchor-permalink" href="#From-Single-Files-to-Many-Files:-The-RAMSES-Challenge" title="Permalink"></a></h2><p>RAMSES simulations create a unique challenge that transforms the I/O bottleneck from bandwidth-limited to <strong>metadata-limited</strong>.</p><h3 id="The-Traditional-RAMSES-Problem"><a class="docs-heading-anchor" href="#The-Traditional-RAMSES-Problem">The Traditional RAMSES Problem</a><a id="The-Traditional-RAMSES-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#The-Traditional-RAMSES-Problem" title="Permalink"></a></h3><pre><code class="nohighlight hljs">
Single RAMSES Output:

├── amr_00250.out00001  ├── hydro_00250.out00001
├── amr_00250.out00002  ├── hydro_00250.out00002
├── amr_00250.out00003  ├── hydro_00250.out00003
...                     ...                      
└── amr_00250.out05120  └── hydro_00250.out05120
------------------------------------------------------------

├── part_00250.out00001 ├── grav_00250.out00001     ...
├── part_00250.out00002 ├── grav_00250.out00002     ... 
├── part_00250.out00003 ├── grav_00250.out00003     ...
...                    ...                      
└── part_00250.out05120 └── grav_00250.out05120     ...
------------------------------------------------------------

Total: 20480 files for a single simulation snapshot!
</code></pre><h3 id="Why-Many-Files-Break-Traditional-I/O"><a class="docs-heading-anchor" href="#Why-Many-Files-Break-Traditional-I/O">Why Many Files Break Traditional I/O</a><a id="Why-Many-Files-Break-Traditional-I/O-1"></a><a class="docs-heading-anchor-permalink" href="#Why-Many-Files-Break-Traditional-I/O" title="Permalink"></a></h3><p><strong>File System Metadata Overhead</strong>:</p><ul><li>Each file requires: open() → read() → close() system calls</li><li>Directory traversal for 1500+ files</li><li>File system locks and metadata updates</li><li>Buffer management for concurrent file handles</li></ul><p><strong>Threading Challenges</strong>:</p><ul><li>Thread contention on file system locks</li><li>Metadata bottlenecks that don&#39;t scale with more threads</li><li>Memory pressure from many concurrent file handles</li></ul><p><strong>Network Storage Amplification</strong>:</p><ul><li>Network latency × number of files = massive overhead</li><li>1000 files × 5ms latency = 5 seconds just for file opens!</li></ul><h3 id="The-Mathematical-Problem"><a class="docs-heading-anchor" href="#The-Mathematical-Problem">The Mathematical Problem</a><a id="The-Mathematical-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#The-Mathematical-Problem" title="Permalink"></a></h3><pre><code class="nohighlight hljs">

# Traditional approach scaling

total_time = n_files × (open_time + read_time + close_time)

# Where open_time and close_time don&#39;t benefit from threading!

# With 1536 files:

# open_time ≈ 1-5ms per file → 1.5-7.5 seconds of pure overhead

# This overhead is largely unparallelizable!
</code></pre><h2 id="Julia&#39;s-Native-Threading-Capabilities"><a class="docs-heading-anchor" href="#Julia&#39;s-Native-Threading-Capabilities">Julia&#39;s Native Threading Capabilities</a><a id="Julia&#39;s-Native-Threading-Capabilities-1"></a><a class="docs-heading-anchor-permalink" href="#Julia&#39;s-Native-Threading-Capabilities" title="Permalink"></a></h2><p>Julia&#39;s threading model is uniquely suited to solve these I/O challenges through its <strong>native, composable design</strong>.</p><h3 id="Why-Julia&#39;s-Threading-Excels"><a class="docs-heading-anchor" href="#Why-Julia&#39;s-Threading-Excels">Why Julia&#39;s Threading Excels</a><a id="Why-Julia&#39;s-Threading-Excels-1"></a><a class="docs-heading-anchor-permalink" href="#Why-Julia&#39;s-Threading-Excels" title="Permalink"></a></h3><p><strong>Automatic Thread Management</strong>:</p><ul><li>No manual thread pool creation</li><li>Automatic work distribution</li><li>Built-in load balancing</li></ul><p><strong>Composable by Design</strong>:</p><ul><li>Libraries work together seamlessly</li><li>No thread pool conflicts</li><li>Automatic resource management</li></ul><p><strong>Memory Efficient</strong>:</p><ul><li>Shared memory model</li><li>Efficient garbage collection</li><li>NUMA-aware scheduling</li></ul><h2 id="Setting-Up-Multi-Threading"><a class="docs-heading-anchor" href="#Setting-Up-Multi-Threading">Setting Up Multi-Threading</a><a id="Setting-Up-Multi-Threading-1"></a><a class="docs-heading-anchor-permalink" href="#Setting-Up-Multi-Threading" title="Permalink"></a></h2><h3 id="Command-Line-Configuration"><a class="docs-heading-anchor" href="#Command-Line-Configuration">Command Line Configuration</a><a id="Command-Line-Configuration-1"></a><a class="docs-heading-anchor-permalink" href="#Command-Line-Configuration" title="Permalink"></a></h3><p>Julia&#39;s threading is configured at startup:</p><pre><code class="nohighlight hljs">

# Specify exact thread count

julia -t 8 your_script.jl
julia --threads 8 your_script.jl

# Auto-detect optimal thread count (Julia 1.7+)

julia -t auto your_script.jl

# Include GC threading (Julia 1.10+)

julia -t 16 --gcthreads 8 your_script.jl
</code></pre><h3 id="Environment-Variables"><a class="docs-heading-anchor" href="#Environment-Variables">Environment Variables</a><a id="Environment-Variables-1"></a><a class="docs-heading-anchor-permalink" href="#Environment-Variables" title="Permalink"></a></h3><pre><code class="nohighlight hljs">

# Linux/macOS

export JULIA_NUM_THREADS=16
export JULIA_NUM_GC_THREADS=8
julia your_script.jl

# Windows

set JULIA_NUM_THREADS=16
set JULIA_NUM_GC_THREADS=8
julia your_script.jl
</code></pre><h3 id="Jupyter-Notebook-Setup"><a class="docs-heading-anchor" href="#Jupyter-Notebook-Setup">Jupyter Notebook Setup</a><a id="Jupyter-Notebook-Setup-1"></a><a class="docs-heading-anchor-permalink" href="#Jupyter-Notebook-Setup" title="Permalink"></a></h3><pre><code class="language-julia hljs">using IJulia

# Install threaded kernels

IJulia.installkernel(&quot;Julia 16t-8gc&quot;,
env=Dict(
&quot;JULIA_NUM_THREADS&quot; =&gt; &quot;16&quot;,
&quot;JULIA_NUM_GC_THREADS&quot; =&gt; &quot;8&quot;)
)
</code></pre><h3 id="Verification"><a class="docs-heading-anchor" href="#Verification">Verification</a><a id="Verification-1"></a><a class="docs-heading-anchor-permalink" href="#Verification" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Base.Threads

# Check threading configuration

println(&quot;Compute threads: &quot;, nthreads())
println(&quot;GC threads: &quot;, ngcthreads())  \# Julia 1.10+
println(&quot;Thread pools: &quot;, nthreadpools())
</code></pre><h2 id="The-Mera-File-Revolution"><a class="docs-heading-anchor" href="#The-Mera-File-Revolution">The Mera File Revolution</a><a id="The-Mera-File-Revolution-1"></a><a class="docs-heading-anchor-permalink" href="#The-Mera-File-Revolution" title="Permalink"></a></h2><p>Understanding the limitations of traditional RAMSES files leads us to Mera.jl&#39;s revolutionary solution: <strong>single compressed JLD2 files</strong>.</p><h3 id="The-Paradigm-Shift"><a class="docs-heading-anchor" href="#The-Paradigm-Shift">The Paradigm Shift</a><a id="The-Paradigm-Shift-1"></a><a class="docs-heading-anchor-permalink" href="#The-Paradigm-Shift" title="Permalink"></a></h3><pre><code class="nohighlight hljs">
Traditional RAMSES:          Mera Format:
1536 files                   1 file
15 GB uncompressed          3-8 GB compressed
1536 open/close operations  1 open/close operation
Complex threading           Optimal threading
</code></pre><h3 id="What-are-Mera-Files?"><a class="docs-heading-anchor" href="#What-are-Mera-Files?">What are Mera Files?</a><a id="What-are-Mera-Files?-1"></a><a class="docs-heading-anchor-permalink" href="#What-are-Mera-Files?" title="Permalink"></a></h3><p>Mera files are <strong>single compressed JLD2 containers</strong> that consolidate all RAMSES simulation data, leveraging Julia&#39;s native JLD2 format for optimal performance.</p><h3 id="Technical-Advantages"><a class="docs-heading-anchor" href="#Technical-Advantages">Technical Advantages</a><a id="Technical-Advantages-1"></a><a class="docs-heading-anchor-permalink" href="#Technical-Advantages" title="Permalink"></a></h3><h4 id="1.-**Elimination-of-Metadata-Overhead**"><a class="docs-heading-anchor" href="#1.-**Elimination-of-Metadata-Overhead**">1. <strong>Elimination of Metadata Overhead</strong></a><a id="1.-**Elimination-of-Metadata-Overhead**-1"></a><a class="docs-heading-anchor-permalink" href="#1.-**Elimination-of-Metadata-Overhead**" title="Permalink"></a></h4><pre><code class="language-julia hljs"># Traditional: 1536 file operations

for cpu in 1:ncpu
hydro[cpu] = read(&quot;hydro_$(cpu).out&quot;)  # 512 operations
    part[cpu] = read(&quot;part_$(cpu).out&quot;)    \# 512 operations
grav[cpu] = read(&quot;grav_\$(cpu).out&quot;)    \# 512 operations
end

# Mera: 1 file operation

mera_data = jldopen(&quot;output_00001.mera&quot;, &quot;r&quot;) do f
(f[&quot;hydro&quot;], f[&quot;particles&quot;], f[&quot;gravity&quot;])  \# Single operation
end
</code></pre><h4 id="2.-**Native-Compression-Support**"><a class="docs-heading-anchor" href="#2.-**Native-Compression-Support**">2. <strong>Native Compression Support</strong></a><a id="2.-**Native-Compression-Support**-1"></a><a class="docs-heading-anchor-permalink" href="#2.-**Native-Compression-Support**" title="Permalink"></a></h4><p>Based on <a href="https://juliaio.github.io/JLD2.jl/dev/compression/">JLD2 compression capabilities</a>:</p><ul><li><strong>LZ4</strong>: Fast compression (2-3x reduction)</li><li><strong>Zlib</strong>: Balanced performance (3-5x reduction)</li><li><strong>Zstd</strong>: Advanced compression (2-8x reduction)</li><li><strong>Selective compression</strong>: Optimize per data type</li></ul><h4 id="3.-**Memory-Mapping-Support**"><a class="docs-heading-anchor" href="#3.-**Memory-Mapping-Support**">3. <strong>Memory Mapping Support</strong></a><a id="3.-**Memory-Mapping-Support**-1"></a><a class="docs-heading-anchor-permalink" href="#3.-**Memory-Mapping-Support**" title="Permalink"></a></h4><pre><code class="language-julia hljs">
# Zero-copy access for large arrays

jldopen(&quot;output.mera&quot;, &quot;r&quot;) do f
positions = f[&quot;positions&quot;]  \# Memory-mapped if uncompressed
\# No memory allocation - direct access to file data!
end
</code></pre><h4 id="4.-**Threading-Optimization**"><a class="docs-heading-anchor" href="#4.-**Threading-Optimization**">4. <strong>Threading Optimization</strong></a><a id="4.-**Threading-Optimization**-1"></a><a class="docs-heading-anchor-permalink" href="#4.-**Threading-Optimization**" title="Permalink"></a></h4><pre><code class="language-julia hljs">
# Parallel component reading

function read_mera_parallel(filename)
jldopen(filename, &quot;r&quot;) do f
\# Different components can be read in parallel
tasks = [
Threads.@spawn f[&quot;hydro&quot;],
Threads.@spawn f[&quot;particles&quot;],
Threads.@spawn f[&quot;gravity&quot;]
]
return fetch.(tasks)
end
end
</code></pre><h3 id="Performance-Revolution"><a class="docs-heading-anchor" href="#Performance-Revolution">Performance Revolution</a><a id="Performance-Revolution-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Revolution" title="Permalink"></a></h3><table><tr><th style="text-align: right">Metric</th><th style="text-align: right">Traditional RAMSES</th><th style="text-align: right">Mera Files</th><th style="text-align: right">Improvement</th></tr><tr><td style="text-align: right">File Operations</td><td style="text-align: right">1536</td><td style="text-align: right">1</td><td style="text-align: right"><strong>1536x</strong></td></tr><tr><td style="text-align: right">Storage Size</td><td style="text-align: right">15 GB</td><td style="text-align: right">3-8 GB</td><td style="text-align: right"><strong>2-5x</strong></td></tr><tr><td style="text-align: right">Threading Efficiency</td><td style="text-align: right">30-50%</td><td style="text-align: right">70-90%</td><td style="text-align: right"><strong>2-3x</strong></td></tr><tr><td style="text-align: right">Network Performance</td><td style="text-align: right">Baseline</td><td style="text-align: right">10-50x faster</td><td style="text-align: right"><strong>10-50x</strong></td></tr><tr><td style="text-align: right">Memory Usage</td><td style="text-align: right">High</td><td style="text-align: right">Low (mmap)</td><td style="text-align: right"><strong>5-10x</strong></td></tr></table><h2 id="Optimal-Threading-Configurations"><a class="docs-heading-anchor" href="#Optimal-Threading-Configurations">Optimal Threading Configurations</a><a id="Optimal-Threading-Configurations-1"></a><a class="docs-heading-anchor-permalink" href="#Optimal-Threading-Configurations" title="Permalink"></a></h2><h3 id="Understanding-the-Sweet-Spots"><a class="docs-heading-anchor" href="#Understanding-the-Sweet-Spots">Understanding the Sweet Spots</a><a id="Understanding-the-Sweet-Spots-1"></a><a class="docs-heading-anchor-permalink" href="#Understanding-the-Sweet-Spots" title="Permalink"></a></h3><p>Threading performance follows predictable patterns based on the underlying bottlenecks:</p><h4 id="Traditional-RAMSES-Files"><a class="docs-heading-anchor" href="#Traditional-RAMSES-Files">Traditional RAMSES Files</a><a id="Traditional-RAMSES-Files-1"></a><a class="docs-heading-anchor-permalink" href="#Traditional-RAMSES-Files" title="Permalink"></a></h4><pre><code class="nohighlight hljs">
| Threads | Efficiency | Bottleneck |
| :-- | :-- | :-- |
| 1-4 | 80-90% | I/O bandwidth |
| 8-12 | 50-70% | File metadata |
| 16+ | 30-50% | File system locks |
</code></pre><h4 id="Mera-Files"><a class="docs-heading-anchor" href="#Mera-Files">Mera Files</a><a id="Mera-Files-1"></a><a class="docs-heading-anchor-permalink" href="#Mera-Files" title="Permalink"></a></h4><pre><code class="nohighlight hljs">
| Threads | Efficiency | Bottleneck |
| :-- | :-- | :-- |
| 1-8 | 85-95% | I/O bandwidth |
| 8-16 | 70-85% | Memory bandwidth |
| 16-32 | 60-75% | CPU/Cache |
| 32+ | 40-60% | Thread overhead |
</code></pre><h3 id="System-Specific-Recommendations"><a class="docs-heading-anchor" href="#System-Specific-Recommendations">System-Specific Recommendations</a><a id="System-Specific-Recommendations-1"></a><a class="docs-heading-anchor-permalink" href="#System-Specific-Recommendations" title="Permalink"></a></h3><table><tr><th style="text-align: right">System Type</th><th style="text-align: right">Traditional RAMSES</th><th style="text-align: right">Mera Files</th><th style="text-align: right">Improvement</th></tr><tr><td style="text-align: right">Laptop (8 cores)</td><td style="text-align: right">4 threads</td><td style="text-align: right">6-8 threads</td><td style="text-align: right"><strong>50% better</strong></td></tr><tr><td style="text-align: right">Workstation (16 cores)</td><td style="text-align: right">6-8 threads</td><td style="text-align: right">12-16 threads</td><td style="text-align: right"><strong>100% better</strong></td></tr><tr><td style="text-align: right">Server (32+ cores)</td><td style="text-align: right">8-12 threads</td><td style="text-align: right">20-32 threads</td><td style="text-align: right"><strong>200% better</strong></td></tr><tr><td style="text-align: right">HPC Node (64+ cores)</td><td style="text-align: right">12-16 threads</td><td style="text-align: right">32-48 threads</td><td style="text-align: right"><strong>300% better</strong></td></tr></table><h3 id="GC-Threading-Optimization"><a class="docs-heading-anchor" href="#GC-Threading-Optimization">GC Threading Optimization</a><a id="GC-Threading-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#GC-Threading-Optimization" title="Permalink"></a></h3><p>Julia 1.10+ introduces garbage collection threading, crucial for large datasets:</p><table><tr><th style="text-align: right">Compute Threads</th><th style="text-align: right">Optimal GC Threads</th><th style="text-align: right">Ratio</th></tr><tr><td style="text-align: right">1-8</td><td style="text-align: right">2-4</td><td style="text-align: right">1:2</td></tr><tr><td style="text-align: right">12-16</td><td style="text-align: right">4-6</td><td style="text-align: right">1:3</td></tr><tr><td style="text-align: right">20-32</td><td style="text-align: right">6-8</td><td style="text-align: right">1:4</td></tr><tr><td style="text-align: right">40-64</td><td style="text-align: right">8-12</td><td style="text-align: right">1:5</td></tr></table><h2 id="Storage-System-Considerations"><a class="docs-heading-anchor" href="#Storage-System-Considerations">Storage System Considerations</a><a id="Storage-System-Considerations-1"></a><a class="docs-heading-anchor-permalink" href="#Storage-System-Considerations" title="Permalink"></a></h2><h3 id="Performance-by-Storage-Technology"><a class="docs-heading-anchor" href="#Performance-by-Storage-Technology">Performance by Storage Technology</a><a id="Performance-by-Storage-Technology-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-by-Storage-Technology" title="Permalink"></a></h3><p>Different storage systems have vastly different optimal threading configurations:</p><h4 id="NVMe-SSD-Systems"><a class="docs-heading-anchor" href="#NVMe-SSD-Systems">NVMe SSD Systems</a><a id="NVMe-SSD-Systems-1"></a><a class="docs-heading-anchor-permalink" href="#NVMe-SSD-Systems" title="Permalink"></a></h4><pre><code class="nohighlight hljs">
Traditional RAMSES: 8-12 threads optimal
Mera Files: 16-32 threads optimal
Improvement: 2-3x better threading scalability
</code></pre><h4 id="Network-File-Systems"><a class="docs-heading-anchor" href="#Network-File-Systems">Network File Systems</a><a id="Network-File-Systems-1"></a><a class="docs-heading-anchor-permalink" href="#Network-File-Systems" title="Permalink"></a></h4><pre><code class="nohighlight hljs">
Traditional RAMSES: 2-4 threads (network latency limited)
Mera Files: 8-16 threads (single file eliminates latency multiplication)
Improvement: 4-8x better threading scalability
</code></pre><h4 id="Hardware-RAID-Systems"><a class="docs-heading-anchor" href="#Hardware-RAID-Systems">Hardware RAID Systems</a><a id="Hardware-RAID-Systems-1"></a><a class="docs-heading-anchor-permalink" href="#Hardware-RAID-Systems" title="Permalink"></a></h4><pre><code class="nohighlight hljs">
Traditional RAMSES: 6-12 threads (controller limited)
Mera Files: 16-32 threads (single large I/O optimal for RAID)
Improvement: 3-5x better threading scalability
</code></pre><h3 id="The-Network-Storage-Revolution"><a class="docs-heading-anchor" href="#The-Network-Storage-Revolution">The Network Storage Revolution</a><a id="The-Network-Storage-Revolution-1"></a><a class="docs-heading-anchor-permalink" href="#The-Network-Storage-Revolution" title="Permalink"></a></h3><p>Mera files transform network storage from the worst-case to competitive:</p><pre><code class="nohighlight hljs">

# Network latency impact

traditional_overhead = n_files × network_latency  \# 1536 × 5ms = 7.68s
mera_overhead = 1 × network_latency              \# 1 × 5ms = 0.005s

# Plus compression reduces transfer time

traditional_transfer = 15_GB ÷ network_bandwidth
mera_transfer = 4_GB ÷ network_bandwidth  \# ~3.75x compression

# Total improvement: 10-50x on network storage!
</code></pre><h2 id="Benchmark-Tools-and-Results"><a class="docs-heading-anchor" href="#Benchmark-Tools-and-Results">Benchmark Tools and Results</a><a id="Benchmark-Tools-and-Results-1"></a><a class="docs-heading-anchor-permalink" href="#Benchmark-Tools-and-Results" title="Permalink"></a></h2><h3 id="Download-and-Run-Benchmarks"><a class="docs-heading-anchor" href="#Download-and-Run-Benchmarks">Download and Run Benchmarks</a><a id="Download-and-Run-Benchmarks-1"></a><a class="docs-heading-anchor-permalink" href="#Download-and-Run-Benchmarks" title="Permalink"></a></h3><pre><code class="nohighlight hljs">

# Clone benchmark suite

git clone https://github.com/ManuelBehrendt/Mera.jl.git
cd Mera.jl/benchmarks

# Test your system

julia -t auto format_comparison.jl
</code></pre><h3 id="Real-World-Performance-Data"><a class="docs-heading-anchor" href="#Real-World-Performance-Data">Real-World Performance Data</a><a id="Real-World-Performance-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Real-World-Performance-Data" title="Permalink"></a></h3><h4 id="Workstation-Comparison-(16-core,-NVMe-SSD)"><a class="docs-heading-anchor" href="#Workstation-Comparison-(16-core,-NVMe-SSD)">Workstation Comparison (16-core, NVMe SSD)</a><a id="Workstation-Comparison-(16-core,-NVMe-SSD)-1"></a><a class="docs-heading-anchor-permalink" href="#Workstation-Comparison-(16-core,-NVMe-SSD)" title="Permalink"></a></h4><p><strong>Traditional RAMSES:</strong></p><pre><code class="nohighlight hljs">
| Threads | Time | Speedup | Efficiency | Issues |
| :-- | :-- | :-- | :-- | :-- |
| 1 | 45.2s | 1.0x | 100% | Baseline |
| 4 | 18.7s | 2.4x | 60% | File metadata overhead |
| 8 | 12.8s | 3.5x | 44% | File system contention |
| 16 | 9.7s | 4.7x | 29% | Severe contention |
</code></pre><p><strong>Mera Files:</strong></p><pre><code class="nohighlight hljs">
| Threads | Time | Speedup | Efficiency | Issues |
| :-- | :-- | :-- | :-- | :-- |
| 1 | 18.3s | 1.0x | 100% | Baseline (already 2.5x faster!) |
| 4 | 5.1s | 3.6x | 90% | Excellent scaling |
| 8 | 2.8s | 6.5x | 81% | Great scaling |
| 16 | 1.6s | 11.4x | 71% | Good scaling |
</code></pre><p><strong>Key insight</strong>: Mera files are 6x faster AND scale better!</p><h4 id="Network-Storage-Comparison-(1-Gbps)"><a class="docs-heading-anchor" href="#Network-Storage-Comparison-(1-Gbps)">Network Storage Comparison (1 Gbps)</a><a id="Network-Storage-Comparison-(1-Gbps)-1"></a><a class="docs-heading-anchor-permalink" href="#Network-Storage-Comparison-(1-Gbps)" title="Permalink"></a></h4><p><strong>Traditional RAMSES:</strong></p><pre><code class="nohighlight hljs">
File operations: 1536 × 5ms latency = 7.68s overhead
Data transfer: 15 GB ÷ 125 MB/s = 120s
Total: ~128s (dominated by latency)
</code></pre><p><strong>Mera Files:</strong></p><pre><code class="nohighlight hljs">
File operations: 1 × 5ms latency = 0.005s overhead
Data transfer: 4 GB ÷ 125 MB/s = 32s
Total: ~32s (4x improvement!)
</code></pre><h2 id="Advanced-Threading-Techniques"><a class="docs-heading-anchor" href="#Advanced-Threading-Techniques">Advanced Threading Techniques</a><a id="Advanced-Threading-Techniques-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-Threading-Techniques" title="Permalink"></a></h2><h3 id="Adaptive-Threading-Based-on-Data-Characteristics"><a class="docs-heading-anchor" href="#Adaptive-Threading-Based-on-Data-Characteristics">Adaptive Threading Based on Data Characteristics</a><a id="Adaptive-Threading-Based-on-Data-Characteristics-1"></a><a class="docs-heading-anchor-permalink" href="#Adaptive-Threading-Based-on-Data-Characteristics" title="Permalink"></a></h3><pre><code class="nohighlight hljs">
function optimal_threading(data_path, system_info)
if is_mera_format(data_path)
\# Mera files scale well
base_threads = min(32, system_info.cpu_cores)
else
\# Traditional RAMSES - conservative
base_threads = min(8, system_info.cpu_cores)
end

    # Adjust for storage type
    if system_info.storage_type == &quot;network&quot;
        return is_mera_format(data_path) ? base_threads : base_threads ÷ 2
    else
        return base_threads
    end
    end
</code></pre><h3 id="Memory-Aware-Processing"><a class="docs-heading-anchor" href="#Memory-Aware-Processing">Memory-Aware Processing</a><a id="Memory-Aware-Processing-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-Aware-Processing" title="Permalink"></a></h3><pre><code class="nohighlight hljs">

# Leverage memory mapping for large Mera files

function process_large_mera(filename; chunk_size=10_000)
jldopen(filename, &quot;r&quot;) do f
positions = f[&quot;positions&quot;]  \# Memory-mapped

        # Process in chunks to manage memory
        Threads.@threads for chunk in Iterators.partition(1:length(positions), chunk_size)
            process_chunk(positions[chunk])  # Zero-copy access
        end
    end
    end
</code></pre><h3 id="Composable-Threading-Patterns"><a class="docs-heading-anchor" href="#Composable-Threading-Patterns">Composable Threading Patterns</a><a id="Composable-Threading-Patterns-1"></a><a class="docs-heading-anchor-permalink" href="#Composable-Threading-Patterns" title="Permalink"></a></h3><pre><code class="nohighlight hljs">

# Julia&#39;s composable threading in action

function analyze_simulation(mera_file)
\# Each function uses optimal internal threading
data = load_mera(mera_file, max_threads=16)        \# I/O threading

    processed = Threads.@threads for component in data  # Processing threading
        analyze_component(component, max_threads=8)     # Analysis threading
    end
    
    # Julia automatically manages the global thread pool
    # No conflicts, no oversubscription!
    return processed
    end
</code></pre><h2 id="Conclusion:-The-Julia-Mera-Advantage"><a class="docs-heading-anchor" href="#Conclusion:-The-Julia-Mera-Advantage">Conclusion: The Julia + Mera Advantage</a><a id="Conclusion:-The-Julia-Mera-Advantage-1"></a><a class="docs-heading-anchor-permalink" href="#Conclusion:-The-Julia-Mera-Advantage" title="Permalink"></a></h2><p>The combination of Julia&#39;s <strong>native parallel computing</strong> capabilities with Mera&#39;s <strong>revolutionary file format</strong> creates a synergistic performance improvement:</p><h3 id="The-Multiplicative-Effect"><a class="docs-heading-anchor" href="#The-Multiplicative-Effect">The Multiplicative Effect</a><a id="The-Multiplicative-Effect-1"></a><a class="docs-heading-anchor-permalink" href="#The-Multiplicative-Effect" title="Permalink"></a></h3><ol><li><strong>Julia&#39;s native threading</strong>: 2-4x improvement over traditional languages</li><li><strong>Mera file format</strong>: 2-6x improvement over traditional RAMSES files  </li><li><strong>Combined effect</strong>: 4-24x total improvement!</li></ol><h3 id="Key-Takeaways"><a class="docs-heading-anchor" href="#Key-Takeaways">Key Takeaways</a><a id="Key-Takeaways-1"></a><a class="docs-heading-anchor-permalink" href="#Key-Takeaways" title="Permalink"></a></h3><ol><li><strong>Julia&#39;s parallel computing is native</strong>: No retrofitted libraries or workarounds</li><li><strong>File format matters enormously</strong>: Mera files eliminate fundamental bottlenecks</li><li><strong>Threading scales better with better I/O</strong>: Single files enable better parallelism</li><li><strong>Composability is crucial</strong>: Julia&#39;s threading &quot;just works&quot; across libraries</li><li><strong>Network storage transformation</strong>: Mera files make network storage viable</li></ol><h3 id="Migration-Path"><a class="docs-heading-anchor" href="#Migration-Path">Migration Path</a><a id="Migration-Path-1"></a><a class="docs-heading-anchor-permalink" href="#Migration-Path" title="Permalink"></a></h3><ol><li><strong>Start with Julia threading</strong>: Immediate 2-4x improvement on existing data</li><li><strong>Convert to Mera format</strong>: Additional 2-6x improvement  </li><li><strong>Optimize thread counts</strong>: Fine-tune for your specific hardware</li><li><strong>Leverage composability</strong>: Combine threaded operations seamlessly</li></ol><p>The future of scientific computing is <strong>native parallelism</strong> + <strong>optimized data formats</strong>. Julia and Mera.jl deliver both today.</p><hr/><p><em>For the latest benchmarks, tools, and documentation, visit the <a href="https://github.com/ManuelBehrendt/Mera.jl">Mera.jl GitHub repository</a>.</em> ```</p><h3 id="Key-Resources-on-Julia-Threading"><a class="docs-heading-anchor" href="#Key-Resources-on-Julia-Threading">Key Resources on Julia Threading</a><a id="Key-Resources-on-Julia-Threading-1"></a><a class="docs-heading-anchor-permalink" href="#Key-Resources-on-Julia-Threading" title="Permalink"></a></h3><ul><li><strong><a href="https://docs.julialang.org/en/v1/manual/multi-threading/">Official Julia Multi-Threading Documentation</a></strong> - Comprehensive guide to Julia&#39;s native threading</li><li><strong><a href="https://docs.julialang.org/en/v1/manual/parallel-computing/">Julia Parallel Computing Overview</a></strong> - All parallel paradigms in Julia</li><li><strong><a href="https://docs.julialang.org/en/v1/base/multi-threading/">Multi-Threading API Reference</a></strong> - Complete threading API</li><li><strong><a href="https://siit.co/blog/mastering-julia-s-parallel-computing-a-deep-dive-into-multiprocessing/10845">Advanced Parallel Patterns</a></strong> - Deep dive into Julia&#39;s parallel capabilities</li></ul><p>: https://www.juliabloggers.com/julias-parallel-processing-2/</p><p>: https://stackoverflow.com/questions/65779503/multi-threading-for-reading-csv-files-in-julia</p><p>: https://docs.julialang.org/en/v1/manual/parallel-computing/</p><p>: https://docs.julialang.org/en/v1/manual/distributed-computing/</p><p>: https://siit.co/blog/mastering-julia-s-parallel-computing-a-deep-dive-into-multiprocessing/10845</p><p>: https://julialang.org</p><p>: https://realpython.com/intro-to-python-threading/</p><p>: https://www.certlibrary.com/blog/understanding-orc-parquet-and-avro-file-formats-in-azure-data-lake/</p><p>: https://docs.julialang.org/en/v1/manual/multi-threading/</p><p>: https://piembsystech.com/parallel-and-distributed-computing-in-julia-programming-language/</p><p>: https://codexterous.home.blog/2021/08/15/thematic-threading-a-strategy-for-annotating-a-text/</p><p>: https://www.tso.de/en/products/document-management/advantages-benefits-m-files/</p><p>: https://www.youtube.com/watch?v=kX6<em>iY</em>BtG8</p><p>: https://book.sciml.ai/notes/06-The<em>Different</em>Flavors<em>of</em>Parallelism/</p><p>: https://softwareengineering.stackexchange.com/questions/380808/how-to-document-multithreaded-applications</p><p>: https://dlmtool.github.io/DLMtool/MERA/MERA<em>User</em>Guide_v6.html</p><p>: http://homepages.math.uic.edu/~jan/mcs507/paralleljulia.pdf</p><p>: https://db.in.tum.de/teaching/ss21/c++praktikum/slides/lecture-10.2.pdf</p><p>: https://dl.acm.org/doi/10.1145/3665330</p><p>: https://discourse.julialang.org/t/help-with-julia-multithreading/109090</p></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Monday 28 July 2025 16:33">Monday 28 July 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
