<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tutorial · Mera.jl</title><meta name="title" content="Tutorial · Mera.jl"/><meta property="og:title" content="Tutorial · Mera.jl"/><meta property="twitter:title" content="Tutorial · Mera.jl"/><meta name="description" content="Documentation for Mera.jl."/><meta property="og:description" content="Documentation for Mera.jl."/><meta property="twitter:description" content="Documentation for Mera.jl."/><meta property="og:url" content="https://manuelbehrendt.github.io/Mera.jl/multi-threading/multi-threading_intro/"/><meta property="twitter:url" content="https://manuelbehrendt.github.io/Mera.jl/multi-threading/multi-threading_intro/"/><link rel="canonical" href="https://manuelbehrendt.github.io/Mera.jl/multi-threading/multi-threading_intro/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/custom.css" rel="stylesheet" type="text/css"/><script src="../../assets/custom.js"></script><script src="../../assets/music_player.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Mera.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../00_multi_FirstSteps/">Getting Started</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Core Workflows</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox"/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">Data Inspection</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../01_hydro_First_Inspection/">Hydro</a></li><li><a class="tocitem" href="../../01_particles_First_Inspection/">Particles</a></li><li><a class="tocitem" href="../../01_clumps_First_Inspection/">Clumps</a></li><li><a class="tocitem" href="../../api/data_inspection/">API Reference</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox"/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Load by Selection</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../02_hydro_Load_Selections/">Hydro</a></li><li><a class="tocitem" href="../../02_particles_Load_Selections/">Particles</a></li><li><a class="tocitem" href="../../02_clumps_Load_Selections/">Clumps</a></li><li><a class="tocitem" href="../../api/data_loading/">API Reference</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Get Subregions</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../03_hydro_Get_Subregions/">Hydro</a></li><li><a class="tocitem" href="../../03_particles_Get_Subregions/">Particles</a></li><li><a class="tocitem" href="../../03_clumps_Get_Subregions/">Clumps</a></li><li><a class="tocitem" href="../../api/subregions/">API Reference</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Analysis &amp; Calculations</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><input class="collapse-toggle" id="menuitem-4-1" type="checkbox"/><label class="tocitem" for="menuitem-4-1"><span class="docs-label">Basic Calculations</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../04_multi_Basic_Calculations/">Tutorial</a></li><li><a class="tocitem" href="../../api/calculations/">API Reference</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-2" type="checkbox"/><label class="tocitem" for="menuitem-4-2"><span class="docs-label">Mask/Filter/Meta</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../05_multi_Masking_Filtering/">Tutorial</a></li><li><a class="tocitem" href="../../api/masking_filtering/">API Reference</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Projection</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../06_hydro_Projection/">Hydro</a></li><li><a class="tocitem" href="../../06_particles_Projection/">Particles</a></li><li><a class="tocitem" href="../../api/projections/">API Reference</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">Data &amp; Visualization</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><input class="collapse-toggle" id="menuitem-5-1" type="checkbox"/><label class="tocitem" for="menuitem-5-1"><span class="docs-label">MERA-Files</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../07_multi_Mera_Files/">Mera-Files</a></li><li><a class="tocitem" href="../../07_1_multi_Mera_Files_Converter/">Converter</a></li><li><a class="tocitem" href="../../api/mera_files/">API Reference</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5-2" type="checkbox"/><label class="tocitem" for="menuitem-5-2"><span class="docs-label">Volume Rendering</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../paraview/paraview_intro/">Intro</a></li><li><a class="tocitem" href="../../paraview/08_hydro_VTK_export/">Hydro</a></li><li><a class="tocitem" href="../../paraview/08_particles_VTK_export/">Particles</a></li><li><a class="tocitem" href="../../api/volume_rendering/">API Reference</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox" checked/><label class="tocitem" for="menuitem-6"><span class="docs-label">Advanced Features</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><input class="collapse-toggle" id="menuitem-6-1" type="checkbox" checked/><label class="tocitem" for="menuitem-6-1"><span class="docs-label">Multi-Threading</span><i class="docs-chevron"></i></label><ul class="collapsed"><li class="is-active"><a class="tocitem" href>Tutorial</a><ul class="internal"><li><a class="tocitem" href="#Quick-Start-Guide"><span>Quick Start Guide</span></a></li><li><a class="tocitem" href="#Quick-Reference"><span>Quick Reference</span></a></li><li><a class="tocitem" href="#Threading-Decision-Framework"><span>Threading Decision Framework</span></a></li><li><a class="tocitem" href="#Self-Assessment-Checkpoints"><span>Self-Assessment Checkpoints</span></a></li><li><a class="tocitem" href="#Try-This:-Hands-On-Threading-Exercises"><span>Try This: Hands-On Threading Exercises</span></a></li><li><a class="tocitem" href="#1-Introduction-to-Multi-Threading-and-GC"><span>1 Introduction to Multi-Threading &amp; GC</span></a></li><li><a class="tocitem" href="#2-Memory-Management-and-Garbage-Collection"><span>2 Memory Management &amp; Garbage Collection</span></a></li><li><a class="tocitem" href="#3-Understanding-Resource-Contention-and-max_threads"><span>3 Understanding Resource Contention &amp; <code>max_threads</code></span></a></li><li><a class="tocitem" href="#4-Setting-Up-Julia-for-Threading"><span>4 Setting Up Julia for Threading</span></a></li><li><a class="tocitem" href="#5-Mera&#39;s-Internally-Threaded-Functions"><span>5 Mera&#39;s Internally Threaded Functions</span></a></li><li><a class="tocitem" href="#6-Core-Threading-Patterns"><span>6 Core Threading Patterns</span></a></li><li><a class="tocitem" href="#7-Advanced-Threading-Patterns"><span>7 Advanced Threading Patterns</span></a></li><li><a class="tocitem" href="#8-Thread-Safe-Programming"><span>8 Thread-Safe Programming</span></a></li><li><a class="tocitem" href="#9-Transforming-Single-Threaded-Tutorials"><span>9 Transforming Single-Threaded Tutorials</span></a></li><li><a class="tocitem" href="#10-Benchmarking-and-Performance-Tuning"><span>10 Benchmarking &amp; Performance Tuning</span></a></li><li><a class="tocitem" href="#11-Best-Practices-and-Troubleshooting"><span>11 Best Practices &amp; Troubleshooting</span></a></li><li><a class="tocitem" href="#12-Complete-Working-Examples"><span>12 Complete Working Examples</span></a></li><li><a class="tocitem" href="#Summary"><span>Summary</span></a></li></ul></li><li><a class="tocitem" href="../../api/multithreading/">API Reference</a></li></ul></li><li><a class="tocitem" href="../../advanced_features/testing_guide/">Testing Framework</a></li><li><input class="collapse-toggle" id="menuitem-6-3" type="checkbox"/><label class="tocitem" for="menuitem-6-3"><span class="docs-label">Notifications</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../notifications/">Overview</a></li><li><a class="tocitem" href="../../notifications/01_quick_start/">Quick Start</a></li><li><a class="tocitem" href="../../notifications/02_setup/">Setup Guide</a></li><li><a class="tocitem" href="../../notifications/bell/">Bell (Local Audio)</a></li><li><a class="tocitem" href="../../notifications/email/">Email</a></li><li><a class="tocitem" href="../../notifications/zulip/">Zulip (Team Chat)</a></li><li><a class="tocitem" href="../../notifications/zulip_templates/">Zulip Templates</a></li><li><a class="tocitem" href="../../notifications/03_attachments/">File Attachments</a></li><li><a class="tocitem" href="../../notifications/04_output_capture/">Output Capture</a></li><li><a class="tocitem" href="../../notifications/05_advanced/">Advanced Features</a></li><li><a class="tocitem" href="../../notifications/06_examples/">Examples</a></li><li><a class="tocitem" href="../../notifications/07_troubleshooting/">Troubleshooting</a></li><li><a class="tocitem" href="../../api/notifications/">API Reference</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6-4" type="checkbox"/><label class="tocitem" for="menuitem-6-4"><span class="docs-label">Benchmarks</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../benchmarks/IO/IOperformance/">Server IO</a></li><li><a class="tocitem" href="../../benchmarks/RAMSES_reading/ramses_reading/">Parallel RAMSES-Files Reading</a></li><li><a class="tocitem" href="../../benchmarks/JLD2_reading/Mera_files_reading/">Mera-Files Reading</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">Julia Quick Reference</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../quickreference/01_getting_started/">Getting Started</a></li><li><a class="tocitem" href="../../quickreference/02_migrators/">From Other Languages</a></li><li><a class="tocitem" href="../../quickreference/03_packages/">Essential Packages</a></li><li><a class="tocitem" href="../../quickreference/04_mera_patterns/">Julia Fundamentals</a></li><li><a class="tocitem" href="../../quickreference/05_performance/">Performance &amp; Debugging</a></li><li><a class="tocitem" href="../../quickreference/06_resources/">Resources &amp; Community</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-8" type="checkbox"/><label class="tocitem" for="menuitem-8"><span class="docs-label">Examples &amp; Reference</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/">Examples</a></li><li><a class="tocitem" href="../../Miscellaneous/">Miscellaneous</a></li><li><a class="tocitem" href="../../api/">Complete API Reference</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Advanced Features</a></li><li><a class="is-disabled">Multi-Threading</a></li><li class="is-active"><a href>Tutorial</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Tutorial</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ManuelBehrendt/Mera.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Multi-Threading-and-Garbage-Collection-in-Mera"><a class="docs-heading-anchor" href="#Multi-Threading-and-Garbage-Collection-in-Mera">Multi-Threading &amp; Garbage Collection in Mera</a><a id="Multi-Threading-and-Garbage-Collection-in-Mera-1"></a><a class="docs-heading-anchor-permalink" href="#Multi-Threading-and-Garbage-Collection-in-Mera" title="Permalink"></a></h1><p><em>Complete guide for high-performance RAMSES simulation analysis with Julia 1.10+</em></p><p><img src="../../assets/representtative_multithreading_60.png" alt="MERA.jl Multi-Threading Performance"/></p><p><em>High-performance parallel computing with MERA.jl: leveraging multi-core processors for accelerated astrophysical data analysis</em></p><p><strong>Main Takeaways</strong>  </p><ul><li>Julia&#39;s <strong>composable threading</strong> and <strong>parallel GC</strong> for multi-GB AMR loads, projections, and VTK exports </li><li>Concurrent threading at multiple levels can saturate I/O and memory—use Mera&#39;s <code>max_threads</code> keyword to control internal concurrency  </li><li><strong>Benchmark</strong> each threaded function to find your server&#39;s optimal thread counts  </li><li>Examples to transform your existing code into parallel workflows with minimal changes</li></ul><h2 id="Quick-Start-Guide"><a class="docs-heading-anchor" href="#Quick-Start-Guide">Quick Start Guide</a><a id="Quick-Start-Guide-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-Start-Guide" title="Permalink"></a></h2><h3 id="For-Complete-Beginners"><a class="docs-heading-anchor" href="#For-Complete-Beginners">For Complete Beginners</a><a id="For-Complete-Beginners-1"></a><a class="docs-heading-anchor-permalink" href="#For-Complete-Beginners" title="Permalink"></a></h3><p><strong>New to Julia threading AND Mera?</strong> Start here:</p><ol><li><strong>Setup</strong>: Start Julia with <code>julia -t auto</code> (uses all available CPU cores)<ul><li><strong>HPC users</strong>: Check core count first with <code>julia -e &quot;println(Sys.CPU_THREADS)&quot;</code>, then use explicit count</li></ul></li><li><strong>Verify</strong>: Run Section 4.1 setup verification </li><li><strong>Learn basics</strong>: Read Sections 1-3 (threading concepts, memory, resource contention)</li><li><strong>Practice fundamentals</strong>: Try Section 6.0 practice exercises</li><li><strong>Understand patterns</strong>: Study Section 6 (outer-loop vs inner-kernel vs mixed)</li><li><strong>Apply</strong>: Use Section 12 complete examples on your data</li></ol><h3 id="For-Julia-Users-New-to-Mera-Threading"><a class="docs-heading-anchor" href="#For-Julia-Users-New-to-Mera-Threading">For Julia Users New to Mera Threading</a><a id="For-Julia-Users-New-to-Mera-Threading-1"></a><a class="docs-heading-anchor-permalink" href="#For-Julia-Users-New-to-Mera-Threading" title="Permalink"></a></h3><p><strong>Know Julia threading but new to Mera?</strong> Follow this path:</p><ol><li><strong>Mera specifics</strong>: Jump to Section 5 (function support and <code>max_threads</code>)</li><li><strong>Practice</strong>: Try Section 6.0 exercises to see Mera patterns</li><li><strong>Choose pattern</strong>: Section 6 for your use case</li><li><strong>Transform code</strong>: Section 9 to adapt existing workflows  </li><li><strong>Optimize</strong>: Section 10 for performance tuning</li></ol><h3 id="For-Experienced-Users"><a class="docs-heading-anchor" href="#For-Experienced-Users">For Experienced Users</a><a id="For-Experienced-Users-1"></a><a class="docs-heading-anchor-permalink" href="#For-Experienced-Users" title="Permalink"></a></h3><p><strong>Already familiar with both?</strong> Quick navigation:</p><ul><li><strong>Reference</strong>: Section 5 (function support), Quick Reference below</li><li><strong>Patterns</strong>: Section 6 (core), Section 7 (advanced)</li><li><strong>Examples</strong>: Section 9 (transformations), Section 12 (production)</li><li><strong>Troubleshooting</strong>: Section 10 (performance), Section 11 (best practices)</li></ul><h3 id="By-Specific-Goal"><a class="docs-heading-anchor" href="#By-Specific-Goal">By Specific Goal</a><a id="By-Specific-Goal-1"></a><a class="docs-heading-anchor-permalink" href="#By-Specific-Goal" title="Permalink"></a></h3><p><strong>What do you want to achieve?</strong></p><ul><li><strong>Process multiple snapshots/parameters</strong> → Section 6.1 (Outer-Loop Pattern)</li><li><strong>Analyze single large dataset</strong> → Section 6.2 (Inner-Kernel Pattern)  </li><li><strong>Build complex multi-stage workflows</strong> → Section 6.3 (Mixed) + Section 7 (Advanced)</li><li><strong>Fix memory/GC issues</strong> → Section 2 (Memory/GC) + Section 11.2 (Troubleshooting)</li><li><strong>Improve performance</strong> → Section 10 (Benchmarking) + Section 11.1 (Best Practices)</li><li><strong>Make existing code threaded</strong> → Section 9 (Tutorial Transformations)</li><li><strong>Thread safety problems</strong> → Section 8 (Thread-Safe Programming)</li></ul><h2 id="Quick-Reference"><a class="docs-heading-anchor" href="#Quick-Reference">Quick Reference</a><a id="Quick-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-Reference" title="Permalink"></a></h2><h3 id="Essential-Commands"><a class="docs-heading-anchor" href="#Essential-Commands">Essential Commands</a><a id="Essential-Commands-1"></a><a class="docs-heading-anchor-permalink" href="#Essential-Commands" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Start Julia with threading
julia -t auto  # Uses all available CPU cores

# Check threading status
using Base.Threads
nthreads()  # Should be &gt; 1

# Basic verification test
@threads for i in 1:nthreads()
    println(&quot;Thread $(threadid()) working&quot;)
end</code></pre><h3 id="Core-Patterns"><a class="docs-heading-anchor" href="#Core-Patterns">Core Patterns</a><a id="Core-Patterns-1"></a><a class="docs-heading-anchor-permalink" href="#Core-Patterns" title="Permalink"></a></h3><table><tr><th style="text-align: right">Pattern</th><th style="text-align: right">When to Use</th><th style="text-align: right">Code Template</th></tr><tr><td style="text-align: right"><strong>Outer-Loop</strong></td><td style="text-align: right">Multiple snapshots/parameters</td><td style="text-align: right"><code>@threads for item in items</code>&lt;br/&gt;<code>mera_func(item; max_threads=1)</code></td></tr><tr><td style="text-align: right"><strong>Inner-Kernel</strong></td><td style="text-align: right">Single large dataset</td><td style="text-align: right"><code>mera_func(data)  # Uses all threads</code>&lt;br/&gt;<code>projection(data, [:var1, :var2])</code></td></tr><tr><td style="text-align: right"><strong>Mixed</strong></td><td style="text-align: right">Controlled resource allocation</td><td style="text-align: right"><code>@spawn mera_func(data; max_threads=N)</code></td></tr></table><h3 id="Function-Threading-Support"><a class="docs-heading-anchor" href="#Function-Threading-Support">Function Threading Support</a><a id="Function-Threading-Support-1"></a><a class="docs-heading-anchor-permalink" href="#Function-Threading-Support" title="Permalink"></a></h3><table><tr><th style="text-align: right">Function</th><th style="text-align: right">Internal Threading</th><th style="text-align: right"><code>max_threads</code></th><th style="text-align: right">Notes</th></tr><tr><td style="text-align: right"><code>gethydro</code></td><td style="text-align: right">✅</td><td style="text-align: right">✅</td><td style="text-align: right">Parallel file loading</td></tr><tr><td style="text-align: right"><code>getgravity</code></td><td style="text-align: right">✅</td><td style="text-align: right">✅</td><td style="text-align: right">Same as gethydro</td></tr><tr><td style="text-align: right"><code>getparticles</code></td><td style="text-align: right">✅</td><td style="text-align: right">✅</td><td style="text-align: right">Same as gethydro</td></tr><tr><td style="text-align: right"><code>projection</code></td><td style="text-align: right">✅</td><td style="text-align: right">✅</td><td style="text-align: right">1 thread per variable</td></tr><tr><td style="text-align: right"><code>export_vtk</code></td><td style="text-align: right">✅</td><td style="text-align: right">✗</td><td style="text-align: right">Auto-threading only</td></tr><tr><td style="text-align: right"><code>getinfo</code></td><td style="text-align: right">✗</td><td style="text-align: right">✗</td><td style="text-align: right">Lightweight, single-thread</td></tr></table><h3 id="Thread-Safe-Data-Collection"><a class="docs-heading-anchor" href="#Thread-Safe-Data-Collection">Thread-Safe Data Collection</a><a id="Thread-Safe-Data-Collection-1"></a><a class="docs-heading-anchor-permalink" href="#Thread-Safe-Data-Collection" title="Permalink"></a></h3><pre><code class="language-julia hljs"># ✅ Safe: Pre-allocated arrays
results = Vector{Float64}(undef, n)
@threads for i in 1:n
    results[i] = compute(i)  # Each thread → different index
end

# ✅ Safe: Atomic operations  
total = Atomic{Float64}(0.0)
@threads for i in 1:n
    atomic_add!(total, compute(i))
end

# ❌ Unsafe: Race conditions
total = 0.0
@threads for i in 1:n
    global total += compute(i)  # Multiple threads → same variable
end</code></pre><h3 id="Common-Gotchas"><a class="docs-heading-anchor" href="#Common-Gotchas">Common Gotchas</a><a id="Common-Gotchas-1"></a><a class="docs-heading-anchor-permalink" href="#Common-Gotchas" title="Permalink"></a></h3><ul><li><strong>Resource contention</strong>: Use <code>max_threads</code> to optimize I/O and memory bandwidth usage</li><li><strong>Memory allocation</strong>: High GC time (&gt;15%) → pre-allocate arrays</li><li><strong>Thread verification</strong>: Always check <code>nthreads() &gt; 1</code> before threading</li><li><strong>Error handling</strong>: Wrap threaded code in <code>try-catch</code> blocks</li></ul><h3 id="Performance-Rules-of-Thumb"><a class="docs-heading-anchor" href="#Performance-Rules-of-Thumb">Performance Rules of Thumb</a><a id="Performance-Rules-of-Thumb-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Rules-of-Thumb" title="Permalink"></a></h3><ul><li><strong>I/O bound</strong>: More threads (4-8) help</li><li><strong>CPU bound</strong>: Match physical cores</li><li><strong>Memory bound</strong>: Fewer threads (2-4) </li><li><strong>Network storage</strong>: Even fewer threads, benefit from compression</li></ul><h2 id="Threading-Decision-Framework"><a class="docs-heading-anchor" href="#Threading-Decision-Framework">Threading Decision Framework</a><a id="Threading-Decision-Framework-1"></a><a class="docs-heading-anchor-permalink" href="#Threading-Decision-Framework" title="Permalink"></a></h2><h3 id="When-TO-Use-Threading"><a class="docs-heading-anchor" href="#When-TO-Use-Threading">When TO Use Threading</a><a id="When-TO-Use-Threading-1"></a><a class="docs-heading-anchor-permalink" href="#When-TO-Use-Threading" title="Permalink"></a></h3><p><strong>✅ Perfect for Threading:</strong></p><ul><li>Processing multiple snapshots/parameters in parallel</li><li>Analyzing single large datasets with multiple variables</li><li>Time series analysis across many simulation outputs</li><li>Parameter sweeps with independent calculations</li><li>I/O-heavy operations (loading, exporting data)</li></ul><p><strong>📊 Threading Decision Tree:</strong></p><pre><code class="nohighlight hljs">Do you have multiple independent tasks?
├─ YES → Use Outer-Loop Pattern (@threads + max_threads=1)
│   └─ Examples: Multiple snapshots, parameter studies
│
└─ NO → Is your dataset large with multiple variables?
    ├─ YES → Use Inner-Kernel Pattern (full threading)
    │   └─ Examples: Multi-variable projections, complex analysis
    │
    └─ NO → Consider Mixed Pattern or stay single-threaded
        └─ Examples: Small datasets, simple calculations</code></pre><h3 id="When-NOT-to-Use-Threading"><a class="docs-heading-anchor" href="#When-NOT-to-Use-Threading">When NOT to Use Threading</a><a id="When-NOT-to-Use-Threading-1"></a><a class="docs-heading-anchor-permalink" href="#When-NOT-to-Use-Threading" title="Permalink"></a></h3><p><strong>❌ Threading Won&#39;t Help:</strong></p><ul><li><strong>Single small calculations</strong> - Threading overhead &gt; benefit</li><li><strong>Memory-starved systems</strong> - Will make GC worse</li><li><strong>Single snapshot + single variable</strong> - Already optimized</li><li><strong>Network bottlenecked I/O</strong> - May actually slow things down</li><li><strong>Thread-unsafe external libraries</strong> - Will cause crashes</li></ul><p><strong>⚖️ Cost-Benefit Analysis:</strong></p><pre><code class="nohighlight hljs">Threading Overhead vs. Parallel Benefit

HIGH BENEFIT:                    LOW/NEGATIVE BENEFIT:
▓▓▓▓▓▓▓▓░░ Many snapshots        ░░▓▓░░░░░░ Single calculation
▓▓▓▓▓▓▓░░░ Large datasets        ░▓▓▓░░░░░░ Small arrays
▓▓▓▓▓▓░░░░ I/O bound tasks       ░░▓▓▓▓░░░░ CPU saturated
▓▓▓▓▓░░░░░ Multiple variables    ░░░▓▓▓▓▓░░ Memory limited</code></pre><p><strong>🧠 Quick Decision Checklist:</strong></p><ol><li><strong>Multiple independent items?</strong> → Threading likely beneficial</li><li><strong>Single item but large/complex?</strong> → Inner parallelism may help</li><li><strong>Small, simple calculation?</strong> → Skip threading</li><li><strong>Unsure?</strong> → Benchmark both approaches (see Section 10)</li></ol><h3 id="Visual-Threading-Concepts"><a class="docs-heading-anchor" href="#Visual-Threading-Concepts">Visual Threading Concepts</a><a id="Visual-Threading-Concepts-1"></a><a class="docs-heading-anchor-permalink" href="#Visual-Threading-Concepts" title="Permalink"></a></h3><p><strong>Thread Pool Allocation:</strong></p><pre><code class="nohighlight hljs">Available Threads: [T1] [T2] [T3] [T4] [T5] [T6] [T7] [T8]

Outer-Loop Pattern:
Snapshot 1 → [T1] gethydro(max_threads=1)
Snapshot 2 → [T2] gethydro(max_threads=1)  
Snapshot 3 → [T3] gethydro(max_threads=1)
Snapshot 4 → [T4] gethydro(max_threads=1)

Inner-Kernel Pattern:
Variable :rho → [T1] [T2] projection
Variable :T   → [T3] [T4] projection
Variable :vx  → [T5] [T6] projection
Variable :vy  → [T7] [T8] projection</code></pre><p><strong>Resource Contention Visualization:</strong></p><pre><code class="nohighlight hljs">Without max_threads (Bad):
Thread 1: [████████████████] I/O + CPU intensive
Thread 2: [████████████████] I/O + CPU intensive  ← Bandwidth fight
Thread 3: [████████████████] I/O + CPU intensive
Thread 4: [████████████████] I/O + CPU intensive

With max_threads=1 (Good):
Thread 1: [████████████████] Full I/O bandwidth
Thread 2: [────────────────] Waiting
Thread 3: [────────────────] Waiting
Thread 4: [────────────────] Waiting</code></pre><h2 id="Self-Assessment-Checkpoints"><a class="docs-heading-anchor" href="#Self-Assessment-Checkpoints">Self-Assessment Checkpoints</a><a id="Self-Assessment-Checkpoints-1"></a><a class="docs-heading-anchor-permalink" href="#Self-Assessment-Checkpoints" title="Permalink"></a></h2><h3 id="Checkpoint-1:-Threading-Readiness"><a class="docs-heading-anchor" href="#Checkpoint-1:-Threading-Readiness">Checkpoint 1: Threading Readiness ✓</a><a id="Checkpoint-1:-Threading-Readiness-1"></a><a class="docs-heading-anchor-permalink" href="#Checkpoint-1:-Threading-Readiness" title="Permalink"></a></h3><p>Before proceeding, verify:</p><ul><li>[ ] Julia started with <code>-t auto</code> (uses all CPU cores) or <code>-t N</code> (explicit count)</li><li>[ ] On HPC clusters: Check <code>Sys.CPU_THREADS</code> and use explicit counts instead of <code>auto</code></li><li>[ ] <code>Threads.nthreads() &gt; 1</code> returns true</li><li>[ ] You understand the difference between outer-loop and inner-kernel patterns</li><li>[ ] You can identify whether your task is I/O, CPU, or memory bound</li></ul><p><strong>Test your setup:</strong></p><pre><code class="language-julia hljs">using Base.Threads
println(&quot;Threads available: $(nthreads())&quot;)
@threads for i in 1:4
    println(&quot;Thread $(threadid()) processing task $i&quot;)
    sleep(0.1)
end</code></pre><h3 id="Checkpoint-2:-Pattern-Selection"><a class="docs-heading-anchor" href="#Checkpoint-2:-Pattern-Selection">Checkpoint 2: Pattern Selection ✓</a><a id="Checkpoint-2:-Pattern-Selection-1"></a><a class="docs-heading-anchor-permalink" href="#Checkpoint-2:-Pattern-Selection" title="Permalink"></a></h3><p>Can you choose the right pattern?</p><p><strong>Scenario A:</strong> Analyze snapshots 100, 200, 300, 400 for total mass</p><ul><li><strong>Your choice:</strong> Outer-loop / Inner-kernel / Mixed?</li><li><strong>Correct:</strong> Outer-loop (<code>@threads</code> over snapshots, <code>max_threads=1</code>)</li></ul><p><strong>Scenario B:</strong> Create density, temperature, and velocity projections from one large dataset</p><ul><li><strong>Your choice:</strong> Outer-loop / Inner-kernel / Mixed?</li><li><strong>Correct:</strong> Inner-kernel (let <code>projection()</code> handle multiple variables)</li></ul><p><strong>Scenario C:</strong> Export VTK files for 10 different spatial regions from the same snapshot</p><ul><li><strong>Your choice:</strong> Outer-loop / Inner-kernel / Mixed?</li><li><strong>Correct:</strong> Mixed or Outer-loop (depends on region size and memory)</li></ul><h2 id="Try-This:-Hands-On-Threading-Exercises"><a class="docs-heading-anchor" href="#Try-This:-Hands-On-Threading-Exercises">Try This: Hands-On Threading Exercises</a><a id="Try-This:-Hands-On-Threading-Exercises-1"></a><a class="docs-heading-anchor-permalink" href="#Try-This:-Hands-On-Threading-Exercises" title="Permalink"></a></h2><h3 id="Exercise-1:-Basic-Threading-Test"><a class="docs-heading-anchor" href="#Exercise-1:-Basic-Threading-Test">Exercise 1: Basic Threading Test</a><a id="Exercise-1:-Basic-Threading-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Exercise-1:-Basic-Threading-Test" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Base.Threads

# Simulate Mera workflow timing
function mock_mera_analysis(snapshot_id)
    thread_id = threadid()
    println(&quot;Thread $thread_id starting snapshot $snapshot_id&quot;)
    
    # Simulate getinfo (fast)
    sleep(0.01)
    
    # Simulate gethydro (slower)  
    sleep(0.2)
    
    # Simulate projection (moderate)
    sleep(0.1)
    
    println(&quot;Thread $thread_id finished snapshot $snapshot_id&quot;)
    return (snapshot=snapshot_id, thread=thread_id, total_mass=rand(1e10:1e12))
end

# Test threaded vs serial
snapshots = 1:8

println(&quot;=== SERIAL VERSION ===&quot;)
@time serial_results = [mock_mera_analysis(s) for s in snapshots]

println(&quot;\n=== THREADED VERSION ===&quot;) 
results = Vector{Any}(undef, length(snapshots))
@time @threads for i in eachindex(snapshots)
    results[i] = mock_mera_analysis(snapshots[i])
end

println(&quot;Speedup: $(length(serial_results)*0.31 / (time_threaded))x&quot;)</code></pre><p><strong>Expected behavior:</strong> You should see multiple thread IDs working simultaneously, and significant speedup.</p><h3 id="Exercise-2:-Resource-Contention-Simulation"><a class="docs-heading-anchor" href="#Exercise-2:-Resource-Contention-Simulation">Exercise 2: Resource Contention Simulation</a><a id="Exercise-2:-Resource-Contention-Simulation-1"></a><a class="docs-heading-anchor-permalink" href="#Exercise-2:-Resource-Contention-Simulation" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Simulate resource contention
function io_heavy_task(task_id, max_threads)
    println(&quot;Task $task_id using max_threads=$max_threads&quot;)
    
    # Simulate heavy I/O (like reading large files)
    if max_threads == 1
        sleep(0.3)  # Serial I/O - efficient
    else
        sleep(0.5)  # Parallel I/O - contention overhead
    end
    
    return &quot;Task $task_id completed&quot;
end

# Compare contention patterns
println(&quot;=== HIGH CONTENTION (max_threads=auto) ===&quot;)
@time @threads for i in 1:8
    io_heavy_task(i, Threads.nthreads())
end

println(&quot;\n=== LOW CONTENTION (max_threads=1) ===&quot;)
@time @threads for i in 1:8
    io_heavy_task(i, 1)
end</code></pre><p><strong>Learning goal:</strong> Understand why <code>max_threads=1</code> can sometimes be faster.</p><h3 id="Exercise-3:-Thread-Safety-Practice"><a class="docs-heading-anchor" href="#Exercise-3:-Thread-Safety-Practice">Exercise 3: Thread Safety Practice</a><a id="Exercise-3:-Thread-Safety-Practice-1"></a><a class="docs-heading-anchor-permalink" href="#Exercise-3:-Thread-Safety-Practice" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Base.Threads

# UNSAFE version - race condition
function unsafe_accumulation(n)
    total = 0.0
    @threads for i in 1:n
        total += i  # DANGER: Multiple threads writing same variable
    end
    return total
end

# SAFE version - atomic operations
function safe_accumulation(n)
    total = Atomic{Float64}(0.0)
    @threads for i in 1:n
        atomic_add!(total, i)
    end
    return total[]
end

# SAFE version - pre-allocated array
function safe_array_accumulation(n)
    results = Vector{Float64}(undef, n)
    @threads for i in 1:n
        results[i] = i  # Safe: each thread writes different index
    end
    return sum(results)
end

# Test all approaches
n = 10000
expected = sum(1:n)

println(&quot;Expected result: $expected&quot;)
println(&quot;Unsafe result: $(unsafe_accumulation(n)) (may be wrong!)&quot;)
println(&quot;Safe atomic result: $(safe_accumulation(n))&quot;)
println(&quot;Safe array result: $(safe_array_accumulation(n))&quot;)</code></pre><p><strong>Learning goal:</strong> See race conditions in action and learn safe alternatives.</p><h2 id="1-Introduction-to-Multi-Threading-and-GC"><a class="docs-heading-anchor" href="#1-Introduction-to-Multi-Threading-and-GC">1 Introduction to Multi-Threading &amp; GC</a><a id="1-Introduction-to-Multi-Threading-and-GC-1"></a><a class="docs-heading-anchor-permalink" href="#1-Introduction-to-Multi-Threading-and-GC" title="Permalink"></a></h2><h3 id="1.1-Why-Multi-Threading-Matters-for-Scientists"><a class="docs-heading-anchor" href="#1.1-Why-Multi-Threading-Matters-for-Scientists">1.1 Why Multi-Threading Matters for Scientists</a><a id="1.1-Why-Multi-Threading-Matters-for-Scientists-1"></a><a class="docs-heading-anchor-permalink" href="#1.1-Why-Multi-Threading-Matters-for-Scientists" title="Permalink"></a></h3><p>Julia&#39;s <strong>native multi-threading</strong> lets you utilize your available cores within pure Julia code—no external libraries, MPI, or complex setup required.</p><p><strong>For Mera users</strong>, this means the following functions are already internally parallelized:</p><ul><li><strong>AMR data loading</strong> (<code>gethydro</code>/<code>getgravity</code>) reads levels concurrently  </li><li><strong>Particle streaming</strong> (<code>getparticles</code>) processes files in parallel  </li><li><strong>Projection creation</strong> (<code>projection</code>) spawns one thread per variable for hydro data</li><li><strong>VTK export</strong> (<code>export_vtk</code>) writes chunks simultaneously  </li></ul><h3 id="1.2-Julia&#39;s-Unique-Advantage:-Composable-Threading"><a class="docs-heading-anchor" href="#1.2-Julia&#39;s-Unique-Advantage:-Composable-Threading">1.2 Julia&#39;s Unique Advantage: Composable Threading</a><a id="1.2-Julia&#39;s-Unique-Advantage:-Composable-Threading-1"></a><a class="docs-heading-anchor-permalink" href="#1.2-Julia&#39;s-Unique-Advantage:-Composable-Threading" title="Permalink"></a></h3><p>Unlike languages that retrofit parallelism, Julia was designed with <strong>composable threading</strong> from the ground up. When one multi-threaded function calls another multi-threaded function, Julia&#39;s scheduler coordinates all threads globally without oversubscribing resources.</p><p>This architectural advantage is crucial for scientific computing where you might:</p><ul><li>Process multiple simulation snapshots simultaneously</li><li>Run different analysis algorithms in parallel  </li><li>Export visualization data while computing results</li><li>Perform parameter sweeps with thousands of iterations</li></ul><h3 id="1.3-Parallel-Garbage-Collection"><a class="docs-heading-anchor" href="#1.3-Parallel-Garbage-Collection">1.3 Parallel Garbage Collection</a><a id="1.3-Parallel-Garbage-Collection-1"></a><a class="docs-heading-anchor-permalink" href="#1.3-Parallel-Garbage-Collection" title="Permalink"></a></h3><p>Julia 1.10+ introduces <strong>parallel garbage collection</strong>—the GC&#39;s mark phase runs on multiple threads, dramatically reducing pause times for allocation-heavy applications. This is especially important when processing large RAMSES datasets that create many temporary objects.</p><h2 id="2-Memory-Management-and-Garbage-Collection"><a class="docs-heading-anchor" href="#2-Memory-Management-and-Garbage-Collection">2 Memory Management &amp; Garbage Collection</a><a id="2-Memory-Management-and-Garbage-Collection-1"></a><a class="docs-heading-anchor-permalink" href="#2-Memory-Management-and-Garbage-Collection" title="Permalink"></a></h2><h3 id="2.1-Stack-vs-Heap-Memory"><a class="docs-heading-anchor" href="#2.1-Stack-vs-Heap-Memory">2.1 Stack vs Heap Memory</a><a id="2.1-Stack-vs-Heap-Memory-1"></a><a class="docs-heading-anchor-permalink" href="#2.1-Stack-vs-Heap-Memory" title="Permalink"></a></h3><p>Understanding Julia&#39;s memory model helps optimize threaded code:</p><p><strong>Memory Architecture Visualization:</strong></p><pre><code class="nohighlight hljs">┌─────────── PROCESS MEMORY SPACE ───────────┐
│                                            │
│  ┌─ STACK (Thread 1) ──┐  ┌─ STACK (Thread 2) ──┐
│  │ function_call()     │  │ function_call()     │
│  │ local_vars = 5.0    │  │ local_vars = 3.2    │
│  │ return_address      │  │ return_address      │
│  │ ▲ GROWS UP          │  │ ▲ GROWS UP          │
│  └─────────────────────┘  └─────────────────────┘
│                                                  │
│  ┌──────── SHARED HEAP (All Threads) ──────────┐
│  │  [Array 1] [Dict 1] [Large Matrix]         │
│  │  [Array 2] [Struct] [String Data]          │
│  │  ┌─ Garbage Collection ─┐                   │
│  │  │ Mark → Sweep → Free  │                   │
│  │  └─────────────────────┘                   │
│  └─────────────────────────────────────────────┘
└────────────────────────────────────────────────┘</code></pre><p><strong>Stack Memory</strong></p><ul><li>Fast, linear LIFO (Last-In-First-Out) structure</li><li>Stores local variables, function parameters, return addresses</li><li>Fixed size, known at compile time</li><li>Automatically freed when function returns</li><li><strong>Thread-safe</strong>: Each thread has its own stack</li></ul><p><strong>Heap Memory</strong>  </p><ul><li>Flexible region for dynamic objects</li><li>Arrays, dictionaries, complex data structures</li><li>Size determined at runtime</li><li>Managed by garbage collector</li><li><strong>Shared</strong>: All threads access the same heap</li></ul><pre><code class="language-julia hljs">function memory_example()
    x = 5.0                    # Stack: small, fixed-size local
    arr = rand(10^6)           # Heap: large, dynamic array
    return sum(arr)            # Stack freed automatically, arr marked for GC
end</code></pre><h3 id="2.2-Julia&#39;s-Garbage-Collector-Explained"><a class="docs-heading-anchor" href="#2.2-Julia&#39;s-Garbage-Collector-Explained">2.2 Julia&#39;s Garbage Collector Explained</a><a id="2.2-Julia&#39;s-Garbage-Collector-Explained-1"></a><a class="docs-heading-anchor-permalink" href="#2.2-Julia&#39;s-Garbage-Collector-Explained" title="Permalink"></a></h3><p>Julia implements a <strong>generational, mark-and-sweep collector</strong>:</p><p><strong>Garbage Collection Visualization:</strong></p><pre><code class="nohighlight hljs">BEFORE GC:                    MARK PHASE:                    SWEEP PHASE:
┌─ HEAP ─────────┐           ┌─ HEAP ─────────┐           ┌─ HEAP ─────────┐
│ [A]━━━━━━━[B]  │  Thread 1 │ [A]✓━━━━━━━[B]✓ │  Thread 1 │ [A]     [B]    │
│  ▲         ▲   │    ┃      │  ▲         ▲   │    ┃      │  ▲       ▲     │
│  ┃         ┗━━━│━━━━┃━━━━━▶│  ┣MARK     ┗━━━│━━━━┣━━━━▶│  ┗━━━━━━━┛      │
│ ROOT      [C]  │  Thread 2 │ ROOT✓    [C]✗  │  Thread 2 │ ROOT      [FREE] │
│            ▲   │    ┃      │            ▲   │    ┃      │           [FREE] │
│           [D]━━│━━━━┗━━━━━▶│           [D]✗━━│━━━━┗━━━━▶│           [FREE] │
└────────────────┘           └────────────────┘           └────────────────┘
   Unreachable objects        ✓=Reachable ✗=Unreachable    Freed memory</code></pre><p><strong>Mark Phase</strong>: Starting from &quot;roots&quot; (global variables, local variables on call stacks), the GC traces all reachable objects. Julia 1.10+ parallelizes this phase across multiple threads.</p><p><strong>Sweep Phase</strong>: Unreachable objects are deallocated and memory returned to the system.</p><p><strong>Generational Strategy</strong>: Most objects die young. The GC focuses on recently allocated objects, which are statistically more likely to be garbage.</p><p><strong>Multi-Threaded GC Benefits:</strong></p><pre><code class="nohighlight hljs">SINGLE-THREADED GC:          PARALLEL GC (Julia 1.10+):
                            
GC Thread: [████████████]    GC Thread 1: [███████]
Program:   [─wait─.......... Program:     [███████] ← Less waiting
                            GC Thread 2: [███████]
Total:     [████████████──]  Total:       [████████] ← Faster overall
           ↑ 12 time units                ↑ 8 time units</code></pre><h3 id="2.3-Monitoring-GC-Performance"><a class="docs-heading-anchor" href="#2.3-Monitoring-GC-Performance">2.3 Monitoring GC Performance</a><a id="2.3-Monitoring-GC-Performance-1"></a><a class="docs-heading-anchor-permalink" href="#2.3-Monitoring-GC-Performance" title="Permalink"></a></h3><p>Use <code>@time</code> to monitor GC impact:</p><pre><code class="language-julia hljs">@time result = analyze_large_dataset(data)
# Output: 2.345 seconds (1.23 M allocations: 456.7 MiB, 15.2% gc time)</code></pre><p>The <strong>15.2% gc time</strong> indicates that over 15% of execution time was spent in garbage collection. Values above 10-20% suggest optimization opportunities.</p><h3 id="2.4-GC-Optimization-Strategies"><a class="docs-heading-anchor" href="#2.4-GC-Optimization-Strategies">2.4 GC Optimization Strategies</a><a id="2.4-GC-Optimization-Strategies-1"></a><a class="docs-heading-anchor-permalink" href="#2.4-GC-Optimization-Strategies" title="Permalink"></a></h3><p><strong>Minimize Allocations</strong></p><pre><code class="language-julia hljs"># BAD: Creates temporary arrays
function inefficient_physics(positions, velocities, masses)
    kinetic = 0.5 .* masses .* (velocities .^ 2)  # Temporary array
    potential = compute_potential(positions)       # Another temporary
    return sum(kinetic) + sum(potential)          # More temporaries
end

# GOOD: Single pass, no allocations  
# No intermediate arrays: every arithmetic operation writes straight into the scalar total
function efficient_physics(positions, velocities, masses)
    total_energy = 0.0
    for i in eachindex(positions)
        total_energy += 0.5 * masses[i] * velocities[i]^2
        total_energy += compute_potential_at(positions[i])
    end
    return total_energy
end</code></pre><h4 id="Allocation-Free-Variants-That-Keep-Broadcasting-Style"><a class="docs-heading-anchor" href="#Allocation-Free-Variants-That-Keep-Broadcasting-Style">-&gt; Allocation-Free Variants That Keep Broadcasting Style</a><a id="Allocation-Free-Variants-That-Keep-Broadcasting-Style-1"></a><a class="docs-heading-anchor-permalink" href="#Allocation-Free-Variants-That-Keep-Broadcasting-Style" title="Permalink"></a></h4><pre><code class="language-Julia hljs"># 1. Fuse Everything and Stream to a Pre-Allocated Vector
# The dotted assignment out .= … fuses all elementwise operations and writes directly into out, so no extra storage is needed
function energy_broadcast!(out, pos, vel, m)
    @. out = 0.5*m*vel^2 + compute_potential_at(pos)
    return sum(out)
end</code></pre><pre><code class="language-Julia hljs"># 2. Map-Reduce Without Intermediates
energy_mapreduce(pos, vel, m) = mapreduce(i -&gt; 0.5*m[i]*vel[i]^2 + compute_potential_at(pos[i]), +, eachindex(pos))</code></pre><p><strong>Preallocate Arrays</strong></p><pre><code class="language-julia hljs"># BAD: Growing arrays cause repeated reallocations
function collect_slow(n)
    results = Float64[]  # Starts empty
    for i in 1:n
        push!(results, expensive_calc(i))  # Repeated reallocations
    end
    return results
end

# GOOD: Allocate once
function collect_fast(n)
    results = Vector{Float64}(undef, n)  # Single allocation
    for i in 1:n
        results[i] = expensive_calc(i)
    end
    return results
end</code></pre><p><strong>Use In-Place Operations</strong></p><pre><code class="language-julia hljs"># BAD: Creates new arrays
function update_slow(state, forces, dt)
    new_vel = state.velocities + forces .* dt      # New array
    new_pos = state.positions + new_vel .* dt      # Another new array
    return SimulationState(new_pos, new_vel)
end

# GOOD: In-place updates
function update_fast!(state, forces, dt)
    @. state.velocities += forces * dt             # In-place
    @. state.positions += state.velocities * dt    # In-place  
    return state
end</code></pre><h2 id="3-Understanding-Resource-Contention-and-max_threads"><a class="docs-heading-anchor" href="#3-Understanding-Resource-Contention-and-max_threads">3 Understanding Resource Contention &amp; <code>max_threads</code></a><a id="3-Understanding-Resource-Contention-and-max_threads-1"></a><a class="docs-heading-anchor-permalink" href="#3-Understanding-Resource-Contention-and-max_threads" title="Permalink"></a></h2><p>Note: With Julia-only threading you typically don&#39;t oversubscribe OS threads; the main risk in nested parallel workflows is resource contention (I/O, memory bandwidth, cache/NUMA).</p><h3 id="3.1-What-Is-Oversubscription?"><a class="docs-heading-anchor" href="#3.1-What-Is-Oversubscription?">3.1 What Is Oversubscription?</a><a id="3.1-What-Is-Oversubscription?-1"></a><a class="docs-heading-anchor-permalink" href="#3.1-What-Is-Oversubscription?" title="Permalink"></a></h3><p><strong>Oversubscription</strong> occurs when you have more runnable threads than physical CPU cores. The operating system must constantly switch between threads, leading to:</p><ul><li><strong>Context switch overhead</strong>: Saving and restoring thread state takes time</li><li><strong>Cache thrashing</strong>: Threads compete for the same CPU caches, reducing efficiency</li><li><strong>Memory bandwidth contention</strong>: Multiple threads saturate memory channels</li><li><strong>False sharing</strong>: Different threads modify variables on the same cache line</li></ul><h3 id="3.2-Why-Resource-Contention-Happens-with-Mera"><a class="docs-heading-anchor" href="#3.2-Why-Resource-Contention-Happens-with-Mera">3.2 Why Resource Contention Happens with Mera</a><a id="3.2-Why-Resource-Contention-Happens-with-Mera-1"></a><a class="docs-heading-anchor-permalink" href="#3.2-Why-Resource-Contention-Happens-with-Mera" title="Permalink"></a></h3><p><strong>Great question!</strong> Julia&#39;s composable threading <em>does</em> work excellently, and since Mera uses only Julia&#39;s native threading capabilities, the scheduler should coordinate everything properly. However, there are still practical scenarios where controlling threading improves performance:</p><p><strong>1. Resource Contention vs Thread Management</strong> Julia prevents creating too many OS threads, but it can&#39;t prevent resource bottlenecks:</p><pre><code class="language-julia hljs"># Julia manages this perfectly at the thread level:
@threads for snapshot in snapshots              # 8 tasks
    gas = gethydro(info; lmax=10)               # Each uses all threads internally
    projection(gas, [:rho, :T, :vx, :vy])      # More internal threading
end
# But all 8 processes hit storage/memory simultaneously</code></pre><p><strong>2. Memory Bandwidth Saturation</strong></p><p><strong>System Resource Bottleneck Visualization:</strong></p><pre><code class="nohighlight hljs">┌─────── CPU CORES (8 available) ────────┐
│ [Core1] [Core2] [Core3] [Core4]        │
│ [Core5] [Core6] [Core7] [Core8]        │  ✓ Usually not the bottleneck
└─────────────────────────────────────────┘
                    │
                    ▼
┌──────── MEMORY BANDWIDTH ──────────────┐
│ RAM: 64 GB                             │
│ Bandwidth: 25.6 GB/s ←── BOTTLENECK   │  ⚠️ Often saturated first!
│ 8 threads × 2GB/s = 16GB/s (63% util) │
└─────────────────────────────────────────┘
                    │
                    ▼
┌─────────── STORAGE I/O ────────────────┐
│ SSD: 500 MB/s                          │
│ Network Storage: 100 MB/s ←── BOTTLENECK│  ⚠️ Worst with many threads
│ 8 concurrent reads = 800 MB/s demand   │
└─────────────────────────────────────────┘</code></pre><p>Multiple threads reading large AMR datasets can saturate:</p><ul><li><strong>Memory bandwidth</strong>: 8 threads × 2GB/thread = 16GB/s (may exceed RAM bandwidth)</li><li><strong>Storage I/O</strong>: Network filesystems often perform better with fewer concurrent readers</li><li><strong>CPU caches</strong>: Context switching between many active memory-intensive tasks</li></ul><p><strong>3. NUMA Effects on Multi-Socket Systems</strong></p><p><strong>NUMA Architecture Visualization:</strong></p><pre><code class="nohighlight hljs">┌─── SOCKET 0 ────┐    ┌─── SOCKET 1 ────┐
│ [CPU0-3] MEM0   │    │ [CPU4-7] MEM1   │
│      ▲          │    │      ▲          │
│      │ FAST     │    │      │ FAST     │
└──────┼──────────┘    └──────┼──────────┘
       │                      │
       └──── SLOW LINK ───────┘
              (QPI/UPI)

OPTIMAL:              SUBOPTIMAL:
Thread1@CPU0 → MEM0   Thread1@CPU0 → MEM1  ← Cross-socket penalty
Thread2@CPU1 → MEM0   Thread2@CPU4 → MEM0  ← Cross-socket penalty</code></pre><p>On large servers with multiple CPU sockets:</p><ul><li>Memory access is faster when threads stay on the same NUMA node</li><li>Too many concurrent threads can cause cross-socket memory traffic</li></ul><p><strong>4. Julia&#39;s Fair Scheduling vs Performance Optimization</strong> Julia&#39;s scheduler is fair but not necessarily optimal for scientific workloads:</p><ul><li>Equal resource sharing among all tasks</li><li>May not account for the specific I/O patterns of large file reads</li></ul><h3 id="3.3-The-max_threads-Solution"><a class="docs-heading-anchor" href="#3.3-The-max_threads-Solution">3.3 The <code>max_threads</code> Solution</a><a id="3.3-The-max_threads-Solution-1"></a><a class="docs-heading-anchor-permalink" href="#3.3-The-max_threads-Solution" title="Permalink"></a></h3><p>Mera functions accept a <code>max_threads::Integer</code> keyword to provide explicit control over resource usage:</p><pre><code class="language-julia hljs"># SOLUTION: Optimize resource usage rather than prevent contention
@threads for snapshot in snapshots              # 8 outer threads (Julia tasks)
    gas = gethydro(info; lmax=10, max_threads=2)    # Limit concurrent I/O
    projection(gas, [:rho, :T]; max_threads=2)      # Control memory pressure
end
# Result: Better memory/I/O utilization patterns</code></pre><p><strong>Why Use <code>max_threads</code> With Julia&#39;s Smart Scheduling?</strong></p><ol><li><strong>I/O Optimization</strong>: Network storage often performs better with fewer concurrent readers</li><li><strong>Memory Bandwidth</strong>: Large datasets benefit from controlled memory access patterns  </li><li><strong>Cache Efficiency</strong>: Fewer active threads = better CPU cache utilization</li><li><strong>NUMA Awareness</strong>: Better memory locality on multi-socket systems</li><li><strong>Performance Tuning</strong>: Precise optimization for your specific hardware and data sizes</li></ol><p><strong><code>max_threads</code> Options:</strong></p><ul><li><code>max_threads = Threads.nthreads()</code> (default): Use all available threads</li><li><code>max_threads = 1</code>: Run completely serially</li><li><code>max_threads = N</code>: Optimize for N concurrent operations</li></ul><p><strong>The Real Benefit</strong>: <code>max_threads</code> isn&#39;t about preventing Julia from breaking - it&#39;s about optimizing for the physical realities of large scientific datasets, storage systems, and memory hierarchies.  </p><h2 id="4-Setting-Up-Julia-for-Threading"><a class="docs-heading-anchor" href="#4-Setting-Up-Julia-for-Threading">4 Setting Up Julia for Threading</a><a id="4-Setting-Up-Julia-for-Threading-1"></a><a class="docs-heading-anchor-permalink" href="#4-Setting-Up-Julia-for-Threading" title="Permalink"></a></h2><h3 id="4.1-Quick-Setup-Verification"><a class="docs-heading-anchor" href="#4.1-Quick-Setup-Verification">4.1 Quick Setup Verification</a><a id="4.1-Quick-Setup-Verification-1"></a><a class="docs-heading-anchor-permalink" href="#4.1-Quick-Setup-Verification" title="Permalink"></a></h3><p><strong>Step 1: Check Your Current Threading Status</strong></p><p>Run this to see your current configuration:</p><pre><code class="language-julia hljs">using Base.Threads

println(&quot;Julia Threading Environment:&quot;)
println(&quot;=&quot; ^ 50)
println(&quot;Number of threads available: &quot;, nthreads())
println(&quot;Thread IDs: &quot;, 1:nthreads())
println(&quot;Current thread: &quot;, threadid())

# Check if we have multiple threads
if nthreads() == 1
    println(&quot;\n⚠️  WARNING: Running with only 1 thread!&quot;)
    println(&quot;To enable multithreading:&quot;)
    println(&quot;1. Exit Julia&quot;)
    println(&quot;2. Restart with: julia -t auto (uses all available CPU cores)&quot;)
    println(&quot;3. Or use: julia -t 4 (for exactly 4 threads)&quot;)
    println(&quot;4. Most benefits of this tutorial require multiple threads&quot;)
else
    println(&quot;\n✅ SUCCESS: Multi-threading is available!&quot;)
    println(&quot;You have &quot;, nthreads(), &quot; threads ready for parallel processing&quot;)
end</code></pre><p><strong>Step 2: Basic Threading Test</strong></p><p>Verify threading works by running this simple test:</p><pre><code class="language-julia hljs"># Basic threading demonstration
println(&quot;\nBasic Threading Test:&quot;)
println(&quot;Available threads: &quot;, nthreads())

# Simple parallel task - each thread identifies itself
@threads for i in 1:nthreads()
    println(&quot;Thread &quot;, threadid(), &quot; processing task &quot;, i)
    sleep(0.1)  # Simulate work
end

println(&quot;✅ Basic threading test completed!&quot;)
println(&quot;Note: If you see output from multiple thread IDs, threading is working correctly.&quot;)</code></pre><h3 id="4.2-Important-Notes-on-Thread-Count-Selection"><a class="docs-heading-anchor" href="#4.2-Important-Notes-on-Thread-Count-Selection">4.2 Important Notes on Thread Count Selection</a><a id="4.2-Important-Notes-on-Thread-Count-Selection-1"></a><a class="docs-heading-anchor-permalink" href="#4.2-Important-Notes-on-Thread-Count-Selection" title="Permalink"></a></h3><div class="admonition is-warning" id="HPC-Cluster-Usage-fc9138b1e9d8314f"><header class="admonition-header">HPC Cluster Usage<a class="admonition-anchor" href="#HPC-Cluster-Usage-fc9138b1e9d8314f" title="Permalink"></a></header><div class="admonition-body"><p><strong>On shared HPC systems and large compute clusters:</strong></p><ul><li><code>julia -t auto</code> uses <strong>ALL available CPU cores</strong> on the node, which may be 32, 64, or more cores</li><li>This can cause <strong>oversubscription</strong> and poor performance on shared systems</li><li>Always check available cores first: <code>julia -e &quot;println(\&quot;CPU cores: \&quot;, Sys.CPU_THREADS)&quot;</code></li><li><strong>Recommended:</strong> Use explicit thread counts instead: <code>julia -t 16</code> or <code>julia -t 32</code></li><li>Consider your job scheduler&#39;s resource allocation (e.g., SLURM <code>--cpus-per-task</code>)</li></ul></div></div><div class="admonition is-success" id="Choosing-Thread-Counts-34363f8bee3edee8"><header class="admonition-header">Choosing Thread Counts<a class="admonition-anchor" href="#Choosing-Thread-Counts-34363f8bee3edee8" title="Permalink"></a></header><div class="admonition-body"><p><strong>Personal computers/workstations:</strong> <code>julia -t auto</code> is usually optimal</p><p><strong>HPC clusters:</strong> Check system resources first:</p><pre><code class="language-bash hljs"># Check total CPU cores
julia -e &quot;println(\&quot;Total CPU cores: \&quot;, Sys.CPU_THREADS)&quot;

# Check NUMA topology (if available)
lscpu | grep -E &quot;CPU\(s\)|NUMA&quot;

# Use explicit counts based on your allocation
julia -t 16  # For 16-core allocation
julia -t 32  # For 32-core allocation</code></pre></div></div><h3 id="4.3-Basic-Thread-Configuration"><a class="docs-heading-anchor" href="#4.3-Basic-Thread-Configuration">4.3 Basic Thread Configuration</a><a id="4.3-Basic-Thread-Configuration-1"></a><a class="docs-heading-anchor-permalink" href="#4.3-Basic-Thread-Configuration" title="Permalink"></a></h3><p>By default, Julia starts with a single thread:</p><pre><code class="language-julia hljs">julia&gt; Threads.nthreads()
1</code></pre><p>Enable multi-threading at startup:</p><pre><code class="language-bash hljs"># Command line argument (recommended)
julia --threads=8                    # 8 threads total
julia --threads=auto                 # Uses all available CPU cores
julia -t 4                          # Short form (explicit count)

# Environment variable method
export JULIA_NUM_THREADS=8
julia</code></pre><h3 id="4.4-Advanced-Configuration-(Julia-1.10)"><a class="docs-heading-anchor" href="#4.4-Advanced-Configuration-(Julia-1.10)">4.4 Advanced Configuration (Julia 1.10+)</a><a id="4.4-Advanced-Configuration-(Julia-1.10)-1"></a><a class="docs-heading-anchor-permalink" href="#4.4-Advanced-Configuration-(Julia-1.10)" title="Permalink"></a></h3><p>Julia 1.10+ supports <strong>two thread pools</strong> and <strong>parallel GC</strong>:</p><pre><code class="language-bash hljs"># 8 compute threads, 2 interactive threads, 4 GC threads
julia --threads=8,2 --gcthreads=4

# Auto-configure everything (recommended for beginners)
julia --threads=auto --gcthreads=auto  # Uses all available CPU cores</code></pre><p><strong>Thread Pools:</strong></p><ul><li><strong><code>:default</code></strong> pool: Compute-intensive tasks</li><li><strong><code>:interactive</code></strong> pool: UI and responsive operations (keeps REPL responsive)</li></ul><p><strong>Verification:</strong></p><pre><code class="language-julia hljs">using Base.Threads

println(&quot;Compute threads: &quot;, nthreads(:default))
println(&quot;Interactive threads: &quot;, nthreads(:interactive))  
println(&quot;Current thread: &quot;, threadid())
println(&quot;Current pool: &quot;, threadpool())
# Note: GC thread count available in Julia 1.10+ with specific functions

# Optimize BLAS for linear algebra
using LinearAlgebra
BLAS.set_num_threads(min(4, nthreads()))
println(&quot;BLAS threads: &quot;, BLAS.get_num_threads())</code></pre><h3 id="4.5-Recommended-Configurations"><a class="docs-heading-anchor" href="#4.5-Recommended-Configurations">4.5 Recommended Configurations</a><a id="4.5-Recommended-Configurations-1"></a><a class="docs-heading-anchor-permalink" href="#4.5-Recommended-Configurations" title="Permalink"></a></h3><p><strong>For laptops/workstations (4-8 cores):</strong></p><pre><code class="language-bash hljs">julia --threads=auto --gcthreads=auto  # Uses all available CPU cores</code></pre><p><strong>For smaller servers (16+ cores):</strong></p><pre><code class="language-bash hljs">julia --threads=12,2 --gcthreads=6</code></pre><p><strong>For larger servers (32+ cores):</strong></p><pre><code class="language-bash hljs">julia --threads=32,4 --gcthreads=16</code></pre><div class="admonition is-warning" id="HPC-Cluster-Configurations-2d7f6111e282728e"><header class="admonition-header">HPC Cluster Configurations<a class="admonition-anchor" href="#HPC-Cluster-Configurations-2d7f6111e282728e" title="Permalink"></a></header><div class="admonition-body"><p><strong>Always use explicit thread counts on shared HPC systems:</strong></p><p><strong>SLURM job with 16 cores:</strong></p><pre><code class="language-bash hljs">#SBATCH --cpus-per-task=16
julia --threads=16,2 --gcthreads=8</code></pre><p><strong>SLURM job with 32 cores:</strong></p><pre><code class="language-bash hljs">#SBATCH --cpus-per-task=32
julia --threads=32,4 --gcthreads=16</code></pre><p><strong>Check your allocation before starting:</strong></p><pre><code class="language-bash hljs">echo &quot;Allocated CPUs: $SLURM_CPUS_PER_TASK&quot;
echo &quot;Total node CPUs: $(nproc)&quot;
julia -e &quot;println(\&quot;Detected CPUs: \&quot;, Sys.CPU_THREADS)&quot;</code></pre><p><strong>Never use <code>julia -t auto</code> on shared nodes</strong> - it may claim all 64+ cores!</p></div></div><h2 id="5-Mera&#39;s-Internally-Threaded-Functions"><a class="docs-heading-anchor" href="#5-Mera&#39;s-Internally-Threaded-Functions">5 Mera&#39;s Internally Threaded Functions</a><a id="5-Mera&#39;s-Internally-Threaded-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#5-Mera&#39;s-Internally-Threaded-Functions" title="Permalink"></a></h2><h3 id="5.1-Overview-of-Threaded-Functions"><a class="docs-heading-anchor" href="#5.1-Overview-of-Threaded-Functions">5.1 Overview of Threaded Functions</a><a id="5.1-Overview-of-Threaded-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#5.1-Overview-of-Threaded-Functions" title="Permalink"></a></h3><p><strong>Mera Function Threading Architecture:</strong></p><pre><code class="nohighlight hljs">┌─ MERA FUNCTION CALL ──────────────────────────────────────────┐
│                                                               │
│  gethydro(info; lmax=10, max_threads=4)                      │
│                     ↓                                         │
│  ┌─ PARALLEL FILE LOADING ─┐   ┌─ PARALLEL TABLE CREATION ─┐  │
│  │ Thread 1: amr_001.out01 │   │ Thread 1: :rho column    │  │
│  │ Thread 2: amr_002.out01 │   │ Thread 2: :vx column     │  │
│  │ Thread 3: amr_003.out01 │   │ Thread 3: :vy column     │  │
│  │ Thread 4: amr_004.out01 │   │ Thread 4: :vz column     │  │
│  └─────────────────────────┘   └───────────────────────────┘  │
│                                                               │
│  projection(gas, [:rho, :T, :vx]; max_threads=3)             │
│                     ↓                                         │
│  ┌─ PARALLEL VARIABLE PROCESSING ──────────────────────────┐  │
│  │ Thread 1: Process :rho → density map                   │  │
│  │ Thread 2: Process :T   → temperature map               │  │
│  │ Thread 3: Process :vx  → velocity map                  │  │
│  └─────────────────────────────────────────────────────────┘  │
└───────────────────────────────────────────────────────────────┘</code></pre><table><tr><th style="text-align: right">Function</th><th style="text-align: right">Threading Strategy</th><th style="text-align: right">Default Threads</th><th style="text-align: right"><code>max_threads</code></th></tr><tr><td style="text-align: right"><code>gethydro</code></td><td style="text-align: right">Parallel across files/levels with dynamic load balancing; final table creation parallel by column</td><td style="text-align: right"><code>Threads.nthreads()</code></td><td style="text-align: right">✓</td></tr><tr><td style="text-align: right"><code>getgravity</code></td><td style="text-align: right">Same strategy as <code>gethydro</code></td><td style="text-align: right"><code>Threads.nthreads()</code></td><td style="text-align: right">✓</td></tr><tr><td style="text-align: right"><code>getparticles</code></td><td style="text-align: right">Same strategy as <code>gethydro</code></td><td style="text-align: right"><code>Threads.nthreads()</code></td><td style="text-align: right">✓</td></tr><tr><td style="text-align: right"><code>projection</code></td><td style="text-align: right">One task per variable (bounded by available/max_threads); dynamic queueing if variables &gt; threads</td><td style="text-align: right"><code>Threads.nthreads()</code></td><td style="text-align: right">✓</td></tr><tr><td style="text-align: right"><code>export_vtk</code></td><td style="text-align: right">Internally threaded (hydro and particles); thread count auto-managed</td><td style="text-align: right"><code>Threads.nthreads()</code></td><td style="text-align: right">✗</td></tr></table><h2 id="6-Core-Threading-Patterns"><a class="docs-heading-anchor" href="#6-Core-Threading-Patterns">6 Core Threading Patterns</a><a id="6-Core-Threading-Patterns-1"></a><a class="docs-heading-anchor-permalink" href="#6-Core-Threading-Patterns" title="Permalink"></a></h2><h3 id="6.0-Quick-Practice:-Threading-Fundamentals"><a class="docs-heading-anchor" href="#6.0-Quick-Practice:-Threading-Fundamentals">6.0 Quick Practice: Threading Fundamentals</a><a id="6.0-Quick-Practice:-Threading-Fundamentals-1"></a><a class="docs-heading-anchor-permalink" href="#6.0-Quick-Practice:-Threading-Fundamentals" title="Permalink"></a></h3><p>Before diving into Mera-specific patterns, let&#39;s practice basic threading concepts:</p><pre><code class="language-julia hljs">using Base.Threads

# Practice 1: Simple parallel simulation
function simulate_mera_workflow(snapshot_name)
    thread_id = threadid()
    println(&quot;Thread $thread_id processing $snapshot_name&quot;)
    
    # Simulate Mera operations with realistic timing
    sleep(0.05)  # getinfo() - fast
    sleep(0.2)   # gethydro() - slower
    sleep(0.1)   # projection() - moderate
    
    return &quot;Processed $snapshot_name on thread $thread_id&quot;
end

# Test external threading pattern
println(&quot;🧪 Testing External Threading Pattern:&quot;)
snapshots = [&quot;snap_001&quot;, &quot;snap_002&quot;, &quot;snap_003&quot;, &quot;snap_004&quot;]
results = Vector{String}(undef, length(snapshots))

start_time = time()
@threads for i in eachindex(snapshots)
    results[i] = simulate_mera_workflow(snapshots[i])
end
elapsed = round(time() - start_time, digits=2)

println(&quot;⏱️  Completed in $(elapsed)s&quot;)
for result in results
    println(&quot;  &quot;, result)
end</code></pre><p><strong>Expected Output:</strong> You should see different thread IDs processing different snapshots simultaneously.</p><h3 id="6.1-Pattern-1:-Outer-Loop-Parallelism"><a class="docs-heading-anchor" href="#6.1-Pattern-1:-Outer-Loop-Parallelism">6.1 Pattern 1: Outer-Loop Parallelism</a><a id="6.1-Pattern-1:-Outer-Loop-Parallelism-1"></a><a class="docs-heading-anchor-permalink" href="#6.1-Pattern-1:-Outer-Loop-Parallelism" title="Permalink"></a></h3><p><strong>When to use:</strong> Processing multiple independent snapshots, parameter combinations, or spatial regions.</p><p><strong>Strategy:</strong> Parallelize the outer loop, disable internal threading.</p><pre><code class="language-julia hljs">using Mera, Base.Threads

# Process multiple snapshots in parallel
snapshots = 100:25:400
results = Vector{NamedTuple}(undef, length(snapshots))

@threads for i in axes(snapshots, 1) # or use : @threads for i in 1:length(snapshots)
    snapshot = snapshots[i]
    info = getinfo(snapshot, SIMPATH)
    
    # Disable internal threading to reduce contention
    gas = gethydro(info; lmax=10, max_threads=1)
    particles = getparticles(info; max_threads=1)
    
    # Perform analysis
    gas_mass = msum(gas, :Msol)
    stellar_mass = msum(particles, :Msol)
    time_myr = gettime(info, :Myr)
    
    results[i] = (
        snapshot = snapshot,
        time_myr = time_myr,
        gas_mass = gas_mass,
        stellar_mass = stellar_mass,
        total_mass = gas_mass + stellar_mass
    )
end</code></pre><h3 id="6.2-Pattern-2:-Inner-Kernel-Parallelism"><a class="docs-heading-anchor" href="#6.2-Pattern-2:-Inner-Kernel-Parallelism">6.2 Pattern 2: Inner-Kernel Parallelism</a><a id="6.2-Pattern-2:-Inner-Kernel-Parallelism-1"></a><a class="docs-heading-anchor-permalink" href="#6.2-Pattern-2:-Inner-Kernel-Parallelism" title="Permalink"></a></h3><p><strong>When to use:</strong> Processing a single large dataset with multiple analysis types.</p><p><strong>Strategy:</strong> Let Mera&#39;s internal threading handle parallelism.</p><pre><code class="language-julia hljs">using Mera

# Load single large dataset with full parallelization
info = getinfo(400, SIMPATH)
gas = gethydro(info; lmax=12)  # Uses all available threads internally

# Create multiple projections - one thread per variable
# Each variable gets its own thread automatically
vars = [:rho, :p, :T, :vx, :vy, :vz]
p = projection(gas, vars; lmax=11) # or use: projections = projection(gas, vars; pxsize=[100., :pc]) </code></pre><h3 id="6.3-Pattern-3:-Mixed-Parallelism"><a class="docs-heading-anchor" href="#6.3-Pattern-3:-Mixed-Parallelism">6.3 Pattern 3: Mixed Parallelism</a><a id="6.3-Pattern-3:-Mixed-Parallelism-1"></a><a class="docs-heading-anchor-permalink" href="#6.3-Pattern-3:-Mixed-Parallelism" title="Permalink"></a></h3><p><strong>When to use:</strong> Balancing multiple tasks with controlled resource allocation.</p><p><strong>Strategy:</strong> Combine outer parallelism with capped inner threading.</p><pre><code class="language-julia hljs">using Mera, Base.Threads

function analyze_simulation_comprehensive(info)
    # Allocate threads carefully across tasks
    tasks = []
    
    # Task 1: Hydro analysis (3 threads)
    push!(tasks, @spawn begin
        gas = gethydro(info; lmax=10, max_threads=3)
        density_proj = projection(gas, :rho; lmax=9, max_threads=2)
        (type=&quot;hydro&quot;, result=density_proj)
    end)
    
    # Task 2: Particle analysis (3 threads)  
    push!(tasks, @spawn begin
        particles = getparticles(info; max_threads=3)
        stellar_mass = msum(particles, :Msol)
        (type=&quot;particles&quot;, result=stellar_mass)
    end)
    
    # Task 3: Export (2 threads)
    # here: reading data again for demonstrating purposes only
    push!(tasks, @spawn begin
        gas = gethydro(info; lmax=8, max_threads=2)
        export_vtk(gas, &quot;output_$(info.output)&quot;;
                  scalars=[:rho, :p])
        (type=&quot;export&quot;, result=&quot;completed&quot;)
    end)
    
    return fetch.(tasks)  # Wait for all tasks to complete
end</code></pre><h2 id="7-Advanced-Threading-Patterns"><a class="docs-heading-anchor" href="#7-Advanced-Threading-Patterns">7 Advanced Threading Patterns</a><a id="7-Advanced-Threading-Patterns-1"></a><a class="docs-heading-anchor-permalink" href="#7-Advanced-Threading-Patterns" title="Permalink"></a></h2><h3 id="7.1-Producer-Consumer-Pipeline"><a class="docs-heading-anchor" href="#7.1-Producer-Consumer-Pipeline">7.1 Producer-Consumer Pipeline</a><a id="7.1-Producer-Consumer-Pipeline-1"></a><a class="docs-heading-anchor-permalink" href="#7.1-Producer-Consumer-Pipeline" title="Permalink"></a></h3><p><strong>Use case:</strong> Streaming data processing with multiple stages.</p><pre><code class="language-julia hljs">using Mera, Base.Threads

function parallel_analysis_pipeline(snapshot_range, SIMPATH, analysis_functions)
    # Stage 1: Data loading (producer)
    data_channel = Channel{NamedTuple}(50)  # Buffered channel
    
    @spawn begin  # Producer task
        @sync for snapshot in snapshot_range
            @spawn begin
                try
                    info = getinfo(snapshot, SIMPATH)
                    gas = gethydro(info; lmax=10, max_threads=1)
                    put!(data_channel, (snapshot=snapshot, gas=gas, info=info))
                catch e
                    @warn &quot;Failed to load snapshot $snapshot: $e&quot;
                end
            end
        end
        close(data_channel)
    end
    
    # Stage 2: Analysis processing (consumers)
    results_channel = Channel{NamedTuple}(25)
    
    @spawn begin
        @sync for _ in 1:nthreads()  # Spawn consumer tasks
            @spawn begin
                for data_item in data_channel
                    try
                        # Apply all analysis functions
                        analysis_results = Dict()
                        for (func_name, func) in analysis_functions
                            analysis_results[func_name] = func(data_item.gas)
                        end
                        
                        put!(results_channel, (
                            snapshot = data_item.snapshot,
                            time_myr = gettime(data_item.info, :Myr),
                            analyses = analysis_results
                        ))
                    catch e
                        @warn &quot;Analysis failed for snapshot $(data_item.snapshot): $e&quot;
                    end
                end
            end
        end
        close(results_channel)
    end
    
    # Collect results
    return collect(results_channel)
end

# Define analysis functions
analysis_functions = [
    (:total_mass, gas -&gt; msum(gas, :Msol)),
    (:mean_density, gas -&gt; mean(getvar(gas, :rho, :nH))),
    (:mass_array, gas -&gt; getvar(gas, :mass))]</code></pre><h3 id="7.2-Adaptive-Load-Balancing"><a class="docs-heading-anchor" href="#7.2-Adaptive-Load-Balancing">7.2 Adaptive Load Balancing</a><a id="7.2-Adaptive-Load-Balancing-1"></a><a class="docs-heading-anchor-permalink" href="#7.2-Adaptive-Load-Balancing" title="Permalink"></a></h3><p><strong>Use case:</strong> Workloads with highly variable execution times (Pseudocode).</p><pre><code class="language-julia hljs">using Mera, Base.Threads

function adaptive_analysis(data_items)
    # Use @spawn for dynamic load balancing
    tasks = []
    
    for item in data_items
        task = @spawn begin
            # Execution time varies greatly by data size
            if estimate_complexity(item) &gt; COMPLEXITY_THRESHOLD
                # Use more resources for complex analysis
                complex_analysis(item; max_threads=4)
            else
                # Simple analysis needs fewer resources  
                simple_analysis(item; max_threads=1)
            end
        end
        push!(tasks, task)
    end
    
    # Fetch all results (tasks complete in variable order)
    return fetch.(tasks)
end</code></pre><p>&lt;!–### 7.3 Hierarchical Parallelism</p><p><strong>Use case:</strong> Multi-level parallel decomposition.</p><pre><code class="language-julia hljs">using Mera, Base.Threads

function hierarchical_analysis(simulation_paths)
    # Level 1: Parallel across simulations
    simulation_tasks = []
    
    for sim_path in simulation_paths
        sim_task = @spawn begin
            snapshots = find_snapshots(sim_path)
            
            # Level 2: Parallel across snapshots within simulation
            snapshot_results = Vector{Any}(undef, length(snapshots))
            @threads for (i, snap) in enumerate(snapshots)
                info = getinfo(snap, sim_path)
                gas = gethydro(info; lmax=9, max_threads=1)  # Serial at level 3
                
                # Level 3: Parallel across variables (controlled)
                vars = [:rho, :T, :p]
                projections = projection(gas, vars; max_threads=2)
                
                snapshot_results[i] = (snapshot=snap, projections=projections)
            end
            
            (simulation=sim_path, results=snapshot_results)
        end
        push!(simulation_tasks, sim_task)
    end
    
    return fetch.(simulation_tasks)
end</code></pre><p>–&gt;</p><h2 id="8-Thread-Safe-Programming"><a class="docs-heading-anchor" href="#8-Thread-Safe-Programming">8 Thread-Safe Programming</a><a id="8-Thread-Safe-Programming-1"></a><a class="docs-heading-anchor-permalink" href="#8-Thread-Safe-Programming" title="Permalink"></a></h2><h3 id="8.0-Quick-Practice:-Thread-Safety-Fundamentals"><a class="docs-heading-anchor" href="#8.0-Quick-Practice:-Thread-Safety-Fundamentals">8.0 Quick Practice: Thread Safety Fundamentals</a><a id="8.0-Quick-Practice:-Thread-Safety-Fundamentals-1"></a><a class="docs-heading-anchor-permalink" href="#8.0-Quick-Practice:-Thread-Safety-Fundamentals" title="Permalink"></a></h3><p>Understanding thread safety is crucial. Let&#39;s see the difference between safe and unsafe operations:</p><pre><code class="language-julia hljs">using Base.Threads

# ❌ UNSAFE: Race condition demonstration
function unsafe_accumulation()
    total = 0
    @threads for i in 1:1000
        total += i  # DANGER: Multiple threads writing to same variable
    end
    return total
end

# ✅ SAFE: Using atomic operations
function safe_accumulation()
    total = Atomic{Int}(0)
    @threads for i in 1:1000
        atomic_add!(total, i)  # SAFE: Atomic operation
    end
    return total[]
end

# ✅ SAFE: Pre-allocated array (each thread writes to different index)
function safe_array_approach()
    results = Vector{Int}(undef, 1000)
    @threads for i in 1:1000
        results[i] = i  # SAFE: Each thread writes to different index
    end
    return sum(results)
end

# Test all approaches
println(&quot;🧪 Thread Safety Demonstration:&quot;)
expected = sum(1:1000)  # Should be 500500

println(&quot;Expected result: &quot;, expected)
println(&quot;Unsafe result: &quot;, unsafe_accumulation(), &quot; (may vary!)&quot;)
println(&quot;Safe atomic result: &quot;, safe_accumulation())
println(&quot;Safe array result: &quot;, safe_array_approach())</code></pre><p><strong>What You&#39;ll Learn:</strong> The unsafe version may give different results each time, while safe versions are consistent.</p><h3 id="8.1-Race-Conditions-and-Thread-Safety"><a class="docs-heading-anchor" href="#8.1-Race-Conditions-and-Thread-Safety">8.1 Race Conditions and Thread Safety</a><a id="8.1-Race-Conditions-and-Thread-Safety-1"></a><a class="docs-heading-anchor-permalink" href="#8.1-Race-Conditions-and-Thread-Safety" title="Permalink"></a></h3><p><strong>Race conditions</strong> occur when multiple threads access shared data simultaneously without synchronization, leading to unpredictable results:</p><pre><code class="language-julia hljs"># DANGEROUS: Race condition
total = 0.0
@threads for i in 1:1_000_000
    global total += compute_value(i)  # Multiple threads writing to same variable
end
println(total)  # Result is unpredictable!</code></pre><h3 id="8.2-Atomic-Operations"><a class="docs-heading-anchor" href="#8.2-Atomic-Operations">8.2 Atomic Operations</a><a id="8.2-Atomic-Operations-1"></a><a class="docs-heading-anchor-permalink" href="#8.2-Atomic-Operations" title="Permalink"></a></h3><p><strong>Atomic variables</strong> provide thread-safe operations for simple data types:</p><pre><code class="language-julia hljs">using Base.Threads

# Thread-safe accumulation using atomics
total = Threads.Atomic{Float64}(0.0)
@threads for i in 1:1_000_000
    value = compute_value(i)
    atomic_add!(total, value)
end
println(&quot;Total: $(total[])&quot;)  # Reliable result</code></pre><pre><code class="language-Julia hljs"># Available atomic operations
counter = Threads.Atomic{Int}(0)
atomic_add!(counter, 5)        # Add 5
atomic_sub!(counter, 2)        # Subtract 2
old_val = atomic_xchg!(counter, 10)  # Exchange values
success = atomic_cas!(counter, 10, 20)  # Compare-and-swap

println(&quot;old_val=&quot;,old_val)
println(&quot; counter=&quot;,counter)
println(&quot; success=&quot;,success)</code></pre><h3 id="8.3-Thread-Safe-Data-Collection-Patterns"><a class="docs-heading-anchor" href="#8.3-Thread-Safe-Data-Collection-Patterns">8.3 Thread-Safe Data Collection Patterns</a><a id="8.3-Thread-Safe-Data-Collection-Patterns-1"></a><a class="docs-heading-anchor-permalink" href="#8.3-Thread-Safe-Data-Collection-Patterns" title="Permalink"></a></h3><p><strong>Pattern 1: Pre-allocated Output Arrays</strong></p><pre><code class="language-julia hljs"># Safe: Each thread writes to different indices
results = Vector{Float64}(undef, n_calculations)
@threads for i in 1:n_calculations
    results[i] = monte_carlo_step(i)  # No race condition
end</code></pre><p><strong>Pattern 2: Thread-Local Accumulators with Atomic Finalization</strong></p><pre><code class="language-julia hljs">using Mera, Base.Threads

function thread_safe_stellar_histogram(particle_data)
    ages = getvar(particle_data, :age, :Myr)
    masses = getvar(particle_data, :mass, :Msol)
    
    # Define bin edges and atomic counters (0-50, 50-100, ..., 450-500 Myr)
    age_edges = collect(0.0:50.0:500.0)
    nbins = length(age_edges) - 1
    mass_per_bin = [Threads.Atomic{Float64}(0.0) for _ in 1:nbins]

    # Thread-safe binning: each thread atomically adds into its bin
    @threads for i in eachindex(ages)
        age = ages[i]
        mass = masses[i]

        bin_index = searchsortedfirst(age_edges, age) - 1
        if 1 &lt;= bin_index &lt;= nbins
            Threads.atomic_add!(mass_per_bin[bin_index], mass)
        end
    end

    # Materialize atomic results into a plain Float64 vector
    return [a[] for a in mass_per_bin]
end</code></pre><h3 id="8.4-Locks-for-Complex-Data-Structures"><a class="docs-heading-anchor" href="#8.4-Locks-for-Complex-Data-Structures">8.4 Locks for Complex Data Structures</a><a id="8.4-Locks-for-Complex-Data-Structures-1"></a><a class="docs-heading-anchor-permalink" href="#8.4-Locks-for-Complex-Data-Structures" title="Permalink"></a></h3><p>For complex shared data structures that can&#39;t use atomics:</p><pre><code class="language-julia hljs">using Base.Threads: ReentrantLock, lock

# Thread-safe access to complex data structures
lk = ReentrantLock()
shared_results = Dict{String, Vector{Float64}}()

@threads for analysis_id in analysis_ids
    result_vector = perform_complex_analysis(analysis_id)
    
    # Thread-safe dictionary update
    lock(lk) do
        shared_results[analysis_id] = result_vector
    end
end</code></pre><h2 id="9-Transforming-Single-Threaded-Tutorials"><a class="docs-heading-anchor" href="#9-Transforming-Single-Threaded-Tutorials">9 Transforming Single-Threaded Tutorials</a><a id="9-Transforming-Single-Threaded-Tutorials-1"></a><a class="docs-heading-anchor-permalink" href="#9-Transforming-Single-Threaded-Tutorials" title="Permalink"></a></h2><h3 id="9.1-Tutorial-Transformation-Overview"><a class="docs-heading-anchor" href="#9.1-Tutorial-Transformation-Overview">9.1 Tutorial Transformation Overview</a><a id="9.1-Tutorial-Transformation-Overview-1"></a><a class="docs-heading-anchor-permalink" href="#9.1-Tutorial-Transformation-Overview" title="Permalink"></a></h3><table><tr><th style="text-align: right">Original Tutorial</th><th style="text-align: right">Multi-Threading Opportunity</th><th style="text-align: right">Pattern Type</th></tr><tr><td style="text-align: right">01<em>hydro</em>First_Inspection.ipynb</td><td style="text-align: right">Load multiple snapshots in parallel</td><td style="text-align: right">Outer-loop</td></tr><tr><td style="text-align: right">02<em>hydro</em>Load_Selections.ipynb</td><td style="text-align: right">Filter multiple regions simultaneously</td><td style="text-align: right">Outer-loop</td></tr><tr><td style="text-align: right">03<em>hydro</em>Get_Subregions.ipynb</td><td style="text-align: right">Extract subregions in parallel</td><td style="text-align: right">Outer-loop</td></tr><tr><td style="text-align: right">06<em>hydro</em>Projection.ipynb</td><td style="text-align: right">Project multiple variables at once</td><td style="text-align: right">Inner-kernel</td></tr><tr><td style="text-align: right">06<em>particles</em>Projection.ipynb</td><td style="text-align: right">Parallel particle projections</td><td style="text-align: right">Mixed</td></tr><tr><td style="text-align: right">08<em>hydro</em>VTK_export.ipynb</td><td style="text-align: right">Export multiple outputs simultaneously</td><td style="text-align: right">Outer-loop</td></tr><tr><td style="text-align: right">08<em>particles</em>VTK_export.ipynb</td><td style="text-align: right">Parallel particle exports</td><td style="text-align: right">Mixed</td></tr></table><h3 id="9.2-Example-1:-Parallel-First-Inspection"><a class="docs-heading-anchor" href="#9.2-Example-1:-Parallel-First-Inspection">9.2 Example 1: Parallel First Inspection</a><a id="9.2-Example-1:-Parallel-First-Inspection-1"></a><a class="docs-heading-anchor-permalink" href="#9.2-Example-1:-Parallel-First-Inspection" title="Permalink"></a></h3><p><em>Transforming 01<em>hydro</em>First_Inspection.ipynb</em></p><p><strong>Original (single-threaded):</strong></p><pre><code class="language-julia hljs">using Mera

# Load and inspect one snapshot
info = getinfo(100, SIMPATH)
gas = gethydro(info; lmax=10)

println(&quot;Time: &quot;, gettime(info, :Myr), &quot; Myr&quot;)
println(&quot;Total mass: &quot;, msum(gas, :Msol), &quot; Msol&quot;)
println(&quot;Number of cells: &quot;, length(gas.data))</code></pre><p><strong>Multi-threaded version:</strong></p><pre><code class="language-julia hljs">using Mera, Base.Threads

# Inspect multiple snapshots in parallel
snapshots = 100:25:400
results = Vector{NamedTuple}(undef, length(snapshots))

@threads for (i, snapshot) in enumerate(snapshots)
    info = getinfo(snapshot, SIMPATH)
    # Use max_threads=1 to reduce contention in outer loop
    gas = gethydro(info; lmax=10, max_threads=1)
    
    results[i] = (
        snapshot = snapshot,
        time_myr = gettime(info, :Myr),
        total_mass = msum(gas, :Msol),
        n_cells = length(gas.data),
        mean_density = mean(getvar(gas, :rho, :nH))
    )
end

# Display results
for r in results
    println(&quot;Snapshot $(r.snapshot): $(r.time_myr) Myr, $(r.total_mass) Msol&quot;)
end</code></pre><h3 id="9.3-Example-2:-Parallel-Selections"><a class="docs-heading-anchor" href="#9.3-Example-2:-Parallel-Selections">9.3 Example 2: Parallel Selections</a><a id="9.3-Example-2:-Parallel-Selections-1"></a><a class="docs-heading-anchor-permalink" href="#9.3-Example-2:-Parallel-Selections" title="Permalink"></a></h3><p><em>Transforming 02<em>hydro</em>Load_Selections.ipynb</em></p><p><strong>Original (single-threaded):</strong></p><pre><code class="language-julia hljs"># Load different spatial selections sequentially
info = getinfo(200, SIMPATH)

# Central region
gas_center = gethydro(info; xrange=[-5,5], yrange=[-5,5], zrange=[-2,2])
mass_center = msum(gas_center, :Msol)

# Disk region  
gas_disk = gethydro(info; xrange=[-10,10], yrange=[-10,10], zrange=[-1,1])
mass_disk = msum(gas_disk, :Msol)</code></pre><p><strong>Multi-threaded version:</strong></p><pre><code class="language-julia hljs">using Mera, Base.Threads

# Define multiple spatial selections
selections = [
    (name=&quot;center&quot;, xrange=[-5,5], yrange=[-5,5], zrange=[-2,2]),
    (name=&quot;disk&quot;, xrange=[-10,10], yrange=[-10,10], zrange=[-1,1]),
    (name=&quot;halo&quot;, xrange=[-25,25], yrange=[-25,25], zrange=[-10,10]),
    (name=&quot;north&quot;, xrange=[-15,15], yrange=[-15,15], zrange=[2,8])
]

results = Vector{NamedTuple}(undef, length(selections))

@threads for (i, sel) in enumerate(selections)
    info = getinfo(200, SIMPATH)
    # Extract selection parameters (excluding name)
    selection_kwargs = [(k,v) for (k,v) in pairs(sel) if k != :name]
    
    gas = gethydro(info; lmax=10, max_threads=1, selection_kwargs...)
    
    results[i] = (
        region = sel.name,
        mass = msum(gas, :Msol),
        volume = (sel.xrange[2]-sel.xrange[1]) * 
                (sel.yrange[2]-sel.yrange[1]) * 
                (sel.zrange[2]-sel.zrange[1]),
        mean_density = mean(getvar(gas, :rho, :nH))
    )
end

# Compare regions
for r in results
    density_msol_pc3 = r.mass / r.volume * (1000/3.086e18)^3
    println(&quot;$(r.region): $(r.mass) Msol, density $(density_msol_pc3) Msol/pc³&quot;)
end</code></pre><h3 id="9.4-Example-3:-Parallel-Projections"><a class="docs-heading-anchor" href="#9.4-Example-3:-Parallel-Projections">9.4 Example 3: Parallel Projections</a><a id="9.4-Example-3:-Parallel-Projections-1"></a><a class="docs-heading-anchor-permalink" href="#9.4-Example-3:-Parallel-Projections" title="Permalink"></a></h3><p><em>Transforming 06<em>hydro</em>Projection.ipynb</em></p><p><strong>Original (single-threaded):</strong></p><pre><code class="language-julia hljs"># Create projections one by one
info = getinfo(300, SIMPATH)
gas = gethydro(info; lmax=11)

# Sequential projections
rho_map = projection(gas, :rho; direction=:z, lmax=9)  
temp_map = projection(gas, :T; direction=:z, lmax=9)
vel_map = projection(gas, :vz; direction=:z, lmax=9)</code></pre><p><strong>Multi-threaded version:</strong></p><pre><code class="language-julia hljs">using Mera

info = getinfo(300, SIMPATH)
gas = gethydro(info; lmax=11)  # Full parallelization for loading

# Create all projections at once - one thread per variable
variables = [:rho, :T, :vz, :p]
projections = projection(gas, variables; direction=:z, lmax=9)

# Access individual projections
# If you pass a single variable, projection(gas, :rho; ...) returns the map directly.
# For multiple variables, access by key if projections is keyed by variable, e.g.:
# rho_map = projections[:rho]

# Alternative: Use @spawn for more control
tasks = [Threads.@spawn projection(gas, var; direction=:z, lmax=9, max_threads=2) 
         for var in variables]
projection_results = fetch.(tasks)</code></pre><h3 id="9.5-Example-4:-Parallel-VTK-Export"><a class="docs-heading-anchor" href="#9.5-Example-4:-Parallel-VTK-Export">9.5 Example 4: Parallel VTK Export</a><a id="9.5-Example-4:-Parallel-VTK-Export-1"></a><a class="docs-heading-anchor-permalink" href="#9.5-Example-4:-Parallel-VTK-Export" title="Permalink"></a></h3><p><em>Transforming 08<em>hydro</em>VTK_export.ipynb</em></p><p><strong>Original (single-threaded):</strong></p><pre><code class="language-julia hljs"># Export one snapshot to VTK
info = getinfo(250, SIMPATH)
gas = gethydro(info; lmax=10)

export_vtk(gas, &quot;hydro_snapshot_250&quot;;
          scalars=[:rho, :p, :T],
          scalars_unit=[:nH, :K, :K])</code></pre><p><strong>Multi-threaded version:</strong></p><pre><code class="language-julia hljs">using Mera, Base.Threads

# Export multiple snapshots in parallel
snapshots = 200:50:400
export_dir = &quot;./vtk_exports&quot;
mkpath(export_dir)  # Create directory

@threads for snapshot in snapshots
    try
        info = getinfo(snapshot, SIMPATH)
        # Load with reduced internal threading
        gas = gethydro(info; lmax=10, max_threads=2)
        
        # Create timestamped filename
        time_myr = gettime(info, :Myr)
        filename = joinpath(export_dir, &quot;hydro_$(snapshot)_t$(time_myr)Myr&quot;)
        
        # VTK export
        export_vtk(gas, filename;
                  scalars=[:rho, :p, :T],
                  scalars_unit=[:nH, :K, :K],
                  vector=[:vx, :vy, :vz],
                  vector_unit=:km_s)
        
        println(&quot;Exported snapshot $snapshot&quot;)
        
    catch e
        @error &quot;Failed to export snapshot $snapshot: $e&quot;
    end
end

println(&quot;VTK export completed for $(length(snapshots)) snapshots&quot;)</code></pre><h2 id="10-Benchmarking-and-Performance-Tuning"><a class="docs-heading-anchor" href="#10-Benchmarking-and-Performance-Tuning">10 Benchmarking &amp; Performance Tuning</a><a id="10-Benchmarking-and-Performance-Tuning-1"></a><a class="docs-heading-anchor-permalink" href="#10-Benchmarking-and-Performance-Tuning" title="Permalink"></a></h2><h3 id="10.1-Finding-Optimal-max_threads-Values"><a class="docs-heading-anchor" href="#10.1-Finding-Optimal-max_threads-Values">10.1 Finding Optimal <code>max_threads</code> Values</a><a id="10.1-Finding-Optimal-max_threads-Values-1"></a><a class="docs-heading-anchor-permalink" href="#10.1-Finding-Optimal-max_threads-Values" title="Permalink"></a></h3><p>Different functions have different optimal thread counts. Benchmark systematically:</p><pre><code class="language-julia hljs">using Mera, BenchmarkTools

function benchmark_gethydro(info)
    println(&quot;Benchmarking gethydro with different max_threads:&quot;)
    for t in (1, 2, 4, 8, Threads.nthreads())
        # Use @belapsed for single measurement (more reliable than @btime here)
        time = @belapsed gethydro($info; lmax=12, max_threads=$t)
        println(&quot;  max_threads=$t → $(round(time, digits=3)) seconds&quot;)
    end
end

function benchmark_projection(gas)
    println(&quot;Benchmarking projection with different max_threads:&quot;)
    vars = [:rho, :T, :vx, :vy]  # 4 variables
    
    for t in (1, 2, 4, 8, min(8, Threads.nthreads()))
        time = @belapsed projection($gas, $vars; lmax=10, max_threads=$t)
        println(&quot;  max_threads=$t → $(round(time, digits=3)) seconds&quot;)
    end
end

function benchmark_export_vtk(gas, temp_prefix)
    println(&quot;Benchmarking export_vtk (note: export_vtk uses internal threading automatically):&quot;)
    
    filename = &quot;$(temp_prefix)_test&quot;
    time = @belapsed begin
        export_vtk($gas, $filename; scalars=[:rho])
        # Clean up
        rm(&quot;$(filename).vti&quot;, force=true)
    end
    println(&quot;  export_vtk time → $(round(time, digits=3)) seconds&quot;)
end

# Run benchmarks
info = getinfo(300, SIMPATH)
gas = gethydro(info; lmax=10, max_threads=1)  # Load once for projection tests

benchmark_gethydro(info)
benchmark_projection(gas)
benchmark_export_vtk(gas, &quot;./benchmark_temp&quot;)</code></pre><p><strong>Example Output:</strong></p><pre><code class="nohighlight hljs">Benchmarking gethydro with different max_threads:
  max_threads=1 → 3.245 seconds
  max_threads=2 → 1.823 seconds
  max_threads=4 → 1.156 seconds
  max_threads=8 → 1.089 seconds
  max_threads=16 → 1.092 seconds

Benchmarking projection with different max_threads:
  max_threads=1 → 2.134 seconds
  max_threads=2 → 1.087 seconds
  max_threads=4 → 0.589 seconds  ← Sweet spot
  max_threads=8 → 0.591 seconds</code></pre><h3 id="10.2-Memory-Usage-Monitoring"><a class="docs-heading-anchor" href="#10.2-Memory-Usage-Monitoring">10.2 Memory Usage Monitoring</a><a id="10.2-Memory-Usage-Monitoring-1"></a><a class="docs-heading-anchor-permalink" href="#10.2-Memory-Usage-Monitoring" title="Permalink"></a></h3><p>Monitor memory allocation and GC performance:</p><pre><code class="language-julia hljs">function monitor_memory_usage(analysis_function, data)
    println(&quot;Memory usage analysis:&quot;)
    
    # Clear previous allocations
    GC.gc()
    
    # Run analysis with detailed timing
    t = @timed analysis_function(data)
    
    allocated_mb = t.bytes / 1024^2
    gc_time_ms = t.gctime * 1000
    
    println(&quot;  Total allocated: $(round(allocated_mb, digits=1)) MB&quot;)
    println(&quot;  GC time: $(round(gc_time_ms, digits=1)) ms&quot;)
    
    if gc_time_ms &gt; 500  # More than 0.5s in GC
        println(&quot;  ⚠️  High GC time detected. Consider:&quot;)
        println(&quot;     - Increasing --gcthreads&quot;)
        println(&quot;     - Pre-allocating arrays&quot;)  
        println(&quot;     - Using in-place operations&quot;)
        println(&quot;     - Processing data in smaller chunks&quot;)
    end
    
    return t.value
end

# Example usage
function test_analysis(snapshots)
    @threads for s in snapshots
        info = getinfo(s, SIMPATH)
        gas = gethydro(info; lmax=10, max_threads=1)
        msum(gas, :Msol)
    end
end

result = monitor_memory_usage(test_analysis, 100:10:150)</code></pre><h3 id="10.3-Thread-Utilization-Analysis"><a class="docs-heading-anchor" href="#10.3-Thread-Utilization-Analysis">10.3 Thread Utilization Analysis</a><a id="10.3-Thread-Utilization-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#10.3-Thread-Utilization-Analysis" title="Permalink"></a></h3><p>Check if threads are being used efficiently:</p><pre><code class="language-julia hljs">using Statistics

function analyze_thread_utilization(workload_function, args...; tasks=Threads.nthreads())
    # Track work distribution across threads
    work_counters = [Threads.Atomic{Int}(0) for _ in 1:Threads.nthreads()]
    
    # Modified workload that tracks thread usage
    function tracked_workload()
        tid = Threads.threadid()
        Threads.atomic_add!(work_counters[tid], 1)
        return workload_function(args...)
    end
    
    # Run the workload across tasks
    start_time = time()
    @threads for _ in 1:tasks
        tracked_workload()
    end
    end_time = time()
    
    # Analyze utilization
    work_counts = [counter[] for counter in work_counters]
    total_work = sum(work_counts)
    
    println(&quot;Thread utilization analysis:&quot;)
    println(&quot;  Total execution time: $(round(end_time - start_time, digits=2))s&quot;)
    println(&quot;  Total work units: $total_work&quot;)
    
    for (i, count) in enumerate(work_counts)
        if count &gt; 0
            percentage = round(count / total_work * 100, digits=1)
            println(&quot;  Thread $i: $count tasks ($(percentage)%)&quot;)
        end
    end
    
    # Load balance coefficient of variation (lower is better)
    active_threads = sum(work_counts .&gt; 0)
    if active_threads &gt; 1
        cv = std(work_counts) / mean(work_counts)
        println(&quot;  Load balance CV: $(round(cv, digits=3)) (lower is better)&quot;)
        
        if cv &gt; 0.5
            println(&quot;  ⚠️  Poor load balance detected. Consider:&quot;)
            println(&quot;     - Using @spawn instead of @threads for variable workloads&quot;)
            println(&quot;     - Reducing task granularity&quot;)
        end
    end
    
    return nothing
end</code></pre><h2 id="11-Best-Practices-and-Troubleshooting"><a class="docs-heading-anchor" href="#11-Best-Practices-and-Troubleshooting">11 Best Practices &amp; Troubleshooting</a><a id="11-Best-Practices-and-Troubleshooting-1"></a><a class="docs-heading-anchor-permalink" href="#11-Best-Practices-and-Troubleshooting" title="Permalink"></a></h2><h3 id="11.1-Threading-Best-Practices"><a class="docs-heading-anchor" href="#11.1-Threading-Best-Practices">11.1 Threading Best Practices</a><a id="11.1-Threading-Best-Practices-1"></a><a class="docs-heading-anchor-permalink" href="#11.1-Threading-Best-Practices" title="Permalink"></a></h3><p><strong>1. Choose One Level of Parallelism</strong></p><pre><code class="language-julia hljs"># GOOD: Outer loop parallelism
@threads for snapshot in snapshots
    gas = gethydro(info; max_threads=1)  # Inner serial
end

# GOOD: Inner parallelism  
gas = gethydro(info)  # Full threads
projections = projection(gas, variables)  # One thread per variable

# AVOID: Uncontrolled nesting
@threads for snapshot in snapshots
    gas = gethydro(info)  # Full threads
    projection(gas, variables)  # More full threads = contention and slowdowns
end</code></pre><p><strong>2. Cap Threads Appropriately</strong></p><pre><code class="language-julia hljs"># Rule of thumb for max_threads:
# - I/O bound: Higher thread counts (4-8)
# - CPU bound: Match physical cores  
# - Memory bound: Lower thread counts (2-4)

export_vtk(gas, filename)                       # Uses internal threading automatically
projection(gas, vars; max_threads=4)            # CPU bound, moderate threads
gethydro(info; max_threads=2)                   # Memory bound, fewer threads</code></pre><p><strong>3. Monitor and Profile</strong></p><pre><code class="language-julia hljs"># Always check GC overhead
@time result = your_analysis_function()
# Look for &quot;% gc time&quot; - keep it under 15%

# Use BenchmarkTools for reliable measurements
@benchmark your_function($args)

# Profile allocation hotspots
using Profile
@profile your_function(args)
Profile.print()</code></pre><p><strong>4. Handle Errors Gracefully</strong></p><pre><code class="language-julia hljs">@threads for item in workload
    try
        process_item(item)
    catch e
        @error &quot;Failed to process $item: $e&quot;
    end
end</code></pre><h3 id="11.2-Common-Issues-and-Solutions"><a class="docs-heading-anchor" href="#11.2-Common-Issues-and-Solutions">11.2 Common Issues and Solutions</a><a id="11.2-Common-Issues-and-Solutions-1"></a><a class="docs-heading-anchor-permalink" href="#11.2-Common-Issues-and-Solutions" title="Permalink"></a></h3><p><strong>Issue 1: Poor Scaling Performance</strong></p><pre><code class="nohighlight hljs">Symptom: Adding more threads doesn&#39;t improve (or worsens) performance</code></pre><p><strong>Causes and Solutions:</strong></p><ul><li><strong>Memory bandwidth bottleneck</strong>: Reduce threads to match memory channels (typically 4-8)</li><li><strong>False sharing</strong>: Use padding or redesign data structures  </li><li><strong>Over-synchronization</strong>: Minimize shared state, use thread-local storage</li><li><strong>I/O contention</strong>: For network storage, fewer threads may be better</li></ul><p><strong>Issue 2: High GC Time</strong></p><pre><code class="nohighlight hljs">Symptom: @time shows &gt;20% gc time</code></pre><p><strong>Solutions:</strong></p><pre><code class="language-julia hljs"># Increase GC threads
# julia --gcthreads=8

# Pre-allocate arrays
results = Vector{Float64}(undef, n)  # Instead of growing with push!

# Use in-place operations  
@. array1 += array2  # Instead of array1 = array1 + array2

# Process in chunks
for chunk in data_chunks
    process(chunk)
    GC.gc()  # Force cleanup between chunks
end</code></pre><p><strong>Issue 3: Crashes or Incorrect Results</strong></p><pre><code class="nohighlight hljs">Symptom: Program crashes, hangs, or produces wrong answers</code></pre><p><strong>Causes and Solutions:</strong></p><ul><li><strong>Race conditions</strong>: Use atomics or locks for shared data</li><li><strong>Unsafe library usage</strong>: Many C libraries aren&#39;t thread-safe  </li><li><strong>Stack overflow</strong>: Large recursion depths on multiple threads</li></ul><h3 id="11.3-Advanced-Debugging-with-verbose_threads"><a class="docs-heading-anchor" href="#11.3-Advanced-Debugging-with-verbose_threads">11.3 Advanced Debugging with <code>verbose_threads</code></a><a id="11.3-Advanced-Debugging-with-verbose_threads-1"></a><a class="docs-heading-anchor-permalink" href="#11.3-Advanced-Debugging-with-verbose_threads" title="Permalink"></a></h3><p>Mera provides powerful built-in debugging capabilities through the <code>verbose_threads</code> parameter.</p><p><strong>Enable Threading Diagnostics</strong></p><pre><code class="language-julia hljs"># Enable detailed threading diagnostics for projections
proj = projection(gas, [:rho, :T, :vx, :vy]; 
                 verbose_threads=true,
                 max_threads=4,
                 verbose=true)</code></pre><p><strong>What <code>verbose_threads=true</code> Shows You:</strong></p><pre><code class="nohighlight hljs">🧵 THREADING DIAGNOSTICS:
====================================
Thread assignment:
  Variable :rho → Thread 1
  Variable :T   → Thread 2  
  Variable :vx  → Thread 3
  Variable :vy  → Thread 4

Load balancing:
  Thread 1: 2.341s (28.5% of total time)
  Thread 2: 2.287s (27.8% of total time)  ← Well balanced
  Thread 3: 2.398s (29.2% of total time)
  Thread 4: 2.195s (26.7% of total time)

Memory allocation per thread:
  Thread 1: 245.7 MB allocated
  Thread 2: 243.1 MB allocated
  Thread 3: 251.2 MB allocated
  Thread 4: 238.9 MB allocated

Performance metrics:
  Total parallel time: 2.398s (max thread time)
  Sequential estimate: 9.221s (sum of thread times)
  Parallel efficiency: 96.2% (excellent)
  Load balance score: 0.94 (0.8+ is good)</code></pre><p><strong>Interpreting Threading Diagnostics:</strong></p><ol><li><p><strong>Load Balance Score:</strong></p><ul><li><code>0.9+</code> = Excellent load balancing</li><li><code>0.8-0.9</code> = Good load balancing  </li><li><code>&lt;0.8</code> = Poor load balancing, consider fewer threads</li></ul></li><li><p><strong>Parallel Efficiency:</strong></p><ul><li><code>90%+</code> = Great threading benefit</li><li><code>70-90%</code> = Reasonable threading benefit</li><li><code>&lt;70%</code> = Threading overhead too high, reduce threads</li></ul></li><li><p><strong>Memory Allocation Patterns:</strong></p><ul><li>Similar allocation across threads = good</li><li>One thread allocating much more = potential bottleneck</li></ul></li></ol><p><strong>Debugging Threading Performance Issues</strong></p><pre><code class="language-julia hljs">using Mera

# Load test data
info = getinfo(400, SIMPATH)  
gas = gethydro(info; lmax=10)

# Test 1: Check if threading helps
println(&quot;=== SINGLE THREAD TEST ===&quot;)
@time proj_serial = projection(gas, [:rho, :T]; 
                               max_threads=1, 
                               verbose_threads=true)

println(&quot;\n=== MULTI THREAD TEST ===&quot;)
@time proj_parallel = projection(gas, [:rho, :T]; 
                                 max_threads=4, 
                                 verbose_threads=true)

# Compare the diagnostics to identify bottlenecks</code></pre><p><strong>Common Issues Diagnosed by <code>verbose_threads</code>:</strong></p><ol><li><strong>Poor Load Balancing:</strong></li></ol><pre><code class="nohighlight hljs">Thread 1: 1.234s (45% of time)  ← Overloaded
Thread 2: 0.892s (32% of time)
Thread 3: 0.634s (23% of time)  ← Underutilized</code></pre><p><strong>Fix:</strong> Use fewer threads or different data partitioning</p><ol><li><strong>Memory Contention:</strong></li></ol><pre><code class="nohighlight hljs">Thread 1: 145.7 MB allocated
Thread 2: 2891.3 MB allocated  ← Memory hog
Thread 3: 151.2 MB allocated</code></pre><p><strong>Fix:</strong> Reduce threads or check for memory leaks in specific variables</p><ol><li><strong>Resource Starvation:</strong></li></ol><pre><code class="nohighlight hljs">Total parallel time: 4.521s
Sequential estimate: 3.987s  ← Parallel slower than serial!
Parallel efficiency: 88.2%</code></pre><p><strong>Fix:</strong> Use <code>max_threads=1</code> or investigate I/O bottlenecks</p><p><strong>Advanced Debugging Tools</strong></p><p><strong>Thread-Safe Debug Output:</strong></p><pre><code class="language-julia hljs">using Base.Threads: SpinLock

debug_lock = SpinLock()
function thread_safe_debug(msg)
    lock(debug_lock) do
        timestamp = round(time(), digits=3)
        println(&quot;[$timestamp] Thread $(threadid()): $msg&quot;)
    end
end

# Use in threaded code
@threads for i in 1:10
    thread_safe_debug(&quot;Starting work on item $i&quot;)
    # ... work ...
    thread_safe_debug(&quot;Completed item $i&quot;)
end</code></pre><p><strong>Performance Profiling with Threading:</strong></p><pre><code class="language-julia hljs">using Profile

# Profile threaded code
@profile begin
    @threads for i in 1:8
        info = getinfo(i*50 + 100, SIMPATH)
        gas = gethydro(info; lmax=9, max_threads=1)
        proj = projection(gas, :rho; max_threads=2, verbose_threads=true)
    end
end

# View profile results
Profile.print()
# Look for thread contention, memory allocation hotspots</code></pre><p><strong>Memory Leak Detection:</strong></p><pre><code class="language-julia hljs">function detect_memory_growth(test_function, n_iterations=10)
    println(&quot;Memory growth analysis:&quot;)
    
    initial_memory = Base.gc_live_bytes()
    println(&quot;Initial memory: $(round(initial_memory/1024^2, digits=2)) MB&quot;)
    
    for i in 1:n_iterations
        test_function()
        GC.gc()  # Force cleanup
        current_memory = Base.gc_live_bytes()
        growth = (current_memory - initial_memory) / 1024^2
        
        println(&quot;Iteration $i: $(round(growth, digits=2)) MB growth&quot;)
        
        if growth &gt; 100  # More than 100MB growth
            @warn &quot;Potential memory leak detected at iteration $i&quot;
        end
    end
end

# Test for memory leaks in threaded code
test_func() = begin
    @threads for i in 1:4
        gas = gethydro(getinfo(100+i, SIMPATH); lmax=8, max_threads=1)
        projection(gas, :rho; verbose_threads=true)
    end
end

detect_memory_growth(test_func)</code></pre><p><strong>Race Condition Detection:</strong></p><pre><code class="language-julia hljs">function test_for_race_conditions(test_function, n_trials=100)
    println(&quot;Testing for race conditions over $n_trials trials...&quot;)
    
    # Get reference result (serial)
    reference_result = test_function()
    
    # Test multiple times
    failures = 0
    for trial in 1:n_trials
        result = test_function()
        if result != reference_result
            failures += 1
            println(&quot;⚠️ Race condition detected in trial $trial!&quot;)
            println(&quot;Expected: $reference_result&quot;)
            println(&quot;Got: $result&quot;)
        end
        
        if trial % 20 == 0
            println(&quot;Completed $trial/$n_trials trials, $failures failures&quot;)
        end
    end
    
    if failures == 0
        println(&quot;✅ No race conditions detected over $n_trials trials&quot;)
    else
        println(&quot;❌ Race conditions detected in $failures/$n_trials trials&quot;)
    end
end</code></pre><p><strong>Threading Environment Diagnostics:</strong></p><pre><code class="language-julia hljs">function diagnose_threading_environment()
    println(&quot;🔍 THREADING ENVIRONMENT DIAGNOSIS&quot;)
    println(&quot;=&quot;^50)
    
    # Basic thread info
    println(&quot;Available threads: $(Threads.nthreads())&quot;)
    println(&quot;CPU cores: $(Sys.CPU_THREADS)&quot;)
    
    # HPC cluster warning
    if Sys.CPU_THREADS &gt; 16 &amp;&amp; Threads.nthreads() == Sys.CPU_THREADS
        println(&quot;⚠️  You&#39;re using all $(Sys.CPU_THREADS) cores - appropriate for personal systems only!&quot;)
        println(&quot;   On HPC clusters, use explicit thread counts to avoid oversubscription&quot;)
    end
    
    # Check for Julia version threading features
    println(&quot;Julia version: $(VERSION)&quot;)
    if VERSION &gt;= v&quot;1.9&quot;
        println(&quot;✅ Composable threading supported&quot;)
    else
        println(&quot;⚠️ Consider upgrading Julia for better threading&quot;)
    end
    
    # Test basic threading
    println(&quot;\n🧪 Basic threading test:&quot;)
    thread_times = Vector{Float64}(undef, Threads.nthreads())
    @threads for i in 1:Threads.nthreads()
        start_time = time()
        sleep(0.1)  # Simulate work
        thread_times[i] = time() - start_time
    end
    
    for (i, t) in enumerate(thread_times)
        println(&quot;Thread $i: $(round(t*1000, digits=1))ms&quot;)
    end
    
    # Check for thread starvation
    if maximum(thread_times) - minimum(thread_times) &gt; 0.05
        println(&quot;⚠️ Potential thread scheduling issues detected&quot;)
    else
        println(&quot;✅ Threading appears to work correctly&quot;)
    end
end

# Run diagnosis
diagnose_threading_environment()</code></pre><h2 id="12-Complete-Working-Examples"><a class="docs-heading-anchor" href="#12-Complete-Working-Examples">12 Complete Working Examples</a><a id="12-Complete-Working-Examples-1"></a><a class="docs-heading-anchor-permalink" href="#12-Complete-Working-Examples" title="Permalink"></a></h2><h3 id="12.1-Multi-Simulation-Analysis-Pipeline"><a class="docs-heading-anchor" href="#12.1-Multi-Simulation-Analysis-Pipeline">12.1 Multi-Simulation Analysis Pipeline</a><a id="12.1-Multi-Simulation-Analysis-Pipeline-1"></a><a class="docs-heading-anchor-permalink" href="#12.1-Multi-Simulation-Analysis-Pipeline" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Mera, Base.Threads
using Statistics, Printf

function comprehensive_analysis_pipeline(simulation_paths)
    &quot;&quot;&quot;
    Complete pipeline: load simulations, analyze multiple snapshots,
    create projections, and export results with full threading control.
    &quot;&quot;&quot;
    
    all_results = Vector{Any}(undef, length(simulation_paths))
    
    # Outer level: Parallel across simulations
    @threads for (j, sim_path) in enumerate(simulation_paths)
        println(&quot;Analyzing simulation: $sim_path&quot;)
        
        try
            # Find available snapshots
            snapshots = find_snapshots_in_path(sim_path)  # Custom function
            sim_results = []
            
            # Process snapshots in this simulation
            for snapshot in snapshots
                info = getinfo(snapshot, sim_path)
                time_myr = gettime(info, :Myr)
                
                # Load data with controlled threading
                gas = gethydro(info; lmax=10, max_threads=2)
                particles = getparticles(info; max_threads=2)
                
                # Parallel projections - one thread per variable
                gas_variables = [:rho, :T, :p]
                gas_projections = projection(gas, gas_variables; 
                                           direction=:z, lmax=9, max_threads=3)
                
                # Particle projection
                particle_proj = projection(particles, :mass; 
                                         direction=:z, max_threads=1)
                
                # Analysis calculations
                gas_mass = msum(gas, :Msol)
                stellar_mass = msum(particles, :Msol)
                mean_density = mean(getvar(gas, :rho, :nH))
                mean_temp = mean(getvar(gas, :T, :K))
                
                # Store results
                push!(sim_results, (
                    snapshot = snapshot,
                    time_myr = time_myr,
                    gas_mass = gas_mass,
                    stellar_mass = stellar_mass,
                    mean_density = mean_density,
                    mean_temperature = mean_temp,
                    gas_projections = gas_projections,
                    particle_projection = particle_proj
                ))
            end
            
            # Write to preallocated slot (thread-safe)
            all_results[j] = (simulation=sim_path, snapshots=sim_results)
            
        catch e
            @error &quot;Failed to analyze simulation $sim_path: $e&quot;
        end
    end
    
    return all_results
end

function find_snapshots_in_path(path)
    # Placeholder - implement based on your file structure
    return 100:50:500
end

# Usage
simulation_paths = [&quot;/data/sim_001&quot;, &quot;/data/sim_002&quot;, &quot;/data/sim_003&quot;]
results = comprehensive_analysis_pipeline(simulation_paths)

# Process results
for sim_result in results
    println(&quot;Simulation: $(sim_result.simulation)&quot;)
    for snap_result in sim_result.snapshots
        @printf(&quot;  t=%.1f Myr: Gas=%.2e Msol, Stars=%.2e Msol, T̄=%.1f K\n&quot;,
                snap_result.time_myr, snap_result.gas_mass, 
                snap_result.stellar_mass, snap_result.mean_temperature)
    end
end</code></pre><h3 id="12.2-Parameter-Study-with-Threading"><a class="docs-heading-anchor" href="#12.2-Parameter-Study-with-Threading">12.2 Parameter Study with Threading</a><a id="12.2-Parameter-Study-with-Threading-1"></a><a class="docs-heading-anchor-permalink" href="#12.2-Parameter-Study-with-Threading" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Mera, Base.Threads

function parallel_parameter_study()
    &quot;&quot;&quot;
    Run analysis across multiple parameter combinations in parallel
    &quot;&quot;&quot;
    
    # Define parameter grid
    lmax_values = [8, 9, 10, 11]
    center_positions = [[24, 24, 24], [25, 25, 25], [23, 23, 23]]
    box_sizes = [5, 10, 15]  # kpc
    
    # Create all parameter combinations
    param_combinations = [(lmax=l, center=c, size=s) 
                         for l in lmax_values 
                         for c in center_positions 
                         for s in box_sizes]
    
    results = Vector{NamedTuple}(undef, length(param_combinations))
    
    # Process parameter combinations in parallel
    @threads for (i, params) in enumerate(param_combinations)
        try
            info = getinfo(300, SIMPATH)
            
            # Load data with parameter-specific settings
            gas = gethydro(info; 
                          lmax = params.lmax,
                          center = params.center,
                          xrange = [-params.size, params.size],
                          yrange = [-params.size, params.size],
                          zrange = [-params.size, params.size],
                          range_unit = :kpc,
                          max_threads = 1)  # Serial inside threaded loop
            
            # Perform analysis
            total_mass = msum(gas, :Msol)
            mean_density = mean(getvar(gas, :rho, :nH))
            n_cells = length(gas.data)
            
            # Create projection
            density_proj = projection(gas, :rho; direction=:z, 
                                    lmax=params.lmax-1, max_threads=2)
            
            # Store results
            results[i] = (
                parameters = params,
                total_mass = total_mass,
                mean_density = mean_density,
                n_cells = n_cells,
                projection = density_proj,
                success = true
            )
            
        catch e
            @error &quot;Parameter combination $params failed: $e&quot;
            results[i] = (parameters=params, success=false, error=e)
        end
    end
    
    # Filter successful results and analyze
    successful_results = filter(r -&gt; r.success, results)
    
    println(&quot;Parameter study completed:&quot;)
    println(&quot;  Total combinations: $(length(param_combinations))&quot;)
    println(&quot;  Successful: $(length(successful_results))&quot;)
    
    # Find optimal parameters (example: maximize resolved cells)
    best_result = findmax(r -&gt; r.n_cells, successful_results)[2]
    
    println(&quot;Best parameters (most cells resolved):&quot;)
    println(&quot;  lmax: $(successful_results[best_result].parameters.lmax)&quot;)
    println(&quot;  center: $(successful_results[best_result].parameters.center)&quot;)  
    println(&quot;  size: $(successful_results[best_result].parameters.size) kpc&quot;)
    println(&quot;  cells: $(successful_results[best_result].n_cells)&quot;)
    
    return successful_results
end

# Run parameter study
study_results = parallel_parameter_study()</code></pre><h3 id="12.3-Time-Series-Analysis-with-Memory-Management"><a class="docs-heading-anchor" href="#12.3-Time-Series-Analysis-with-Memory-Management">12.3 Time Series Analysis with Memory Management</a><a id="12.3-Time-Series-Analysis-with-Memory-Management-1"></a><a class="docs-heading-anchor-permalink" href="#12.3-Time-Series-Analysis-with-Memory-Management" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Mera, Base.Threads
using Statistics

function memory_efficient_time_series(snapshot_range, chunk_size=5)
    &quot;&quot;&quot;
    Process time series in chunks to manage memory usage
    &quot;&quot;&quot;
    
    # Pre-allocate result arrays  
    n_snapshots = length(snapshot_range)
    times = Vector{Float64}(undef, n_snapshots)
    gas_masses = Vector{Float64}(undef, n_snapshots)
    stellar_masses = Vector{Float64}(undef, n_snapshots)
    mean_densities = Vector{Float64}(undef, n_snapshots)
    mean_temperatures = Vector{Float64}(undef, n_snapshots)
    
    # Process in chunks to manage memory
    for chunk_start in 1:chunk_size:n_snapshots
        chunk_end = min(chunk_start + chunk_size - 1, n_snapshots)
        chunk_indices = chunk_start:chunk_end
        
        println(&quot;Processing chunk $(chunk_start):$(chunk_end)&quot;)
        
        # Process chunk in parallel
        @threads for i in chunk_indices
            snapshot = snapshot_range[i]
            
            try
                info = getinfo(snapshot, SIMPATH)
                
                # Load data with memory-conscious settings
                gas = gethydro(info; lmax=10, max_threads=1)
                particles = getparticles(info; max_threads=1)
                
                # Extract variables efficiently
                gas_rho = getvar(gas, :rho, :nH)
                gas_temp = getvar(gas, :T, :K)
                gas_mass_vals = getvar(gas, :mass, :Msol)
                particle_masses = getvar(particles, :mass, :Msol)
                
                # Compute and store results
                times[i] = gettime(info, :Myr)
                gas_masses[i] = sum(gas_mass_vals)
                stellar_masses[i] = sum(particle_masses)
                mean_densities[i] = mean(gas_rho)
                mean_temperatures[i] = mean(gas_temp)
                
            catch e
                @error &quot;Failed to process snapshot $snapshot: $e&quot;
                # Fill with NaN for failed snapshots
                times[i] = NaN
                gas_masses[i] = NaN  
                stellar_masses[i] = NaN
                mean_densities[i] = NaN
                mean_temperatures[i] = NaN
            end
        end
        
        # Force garbage collection between chunks
        GC.gc()
        println(&quot;Chunk completed, memory freed&quot;)
    end
    
    # Filter out failed snapshots
    valid_indices = .!isnan.(times)
    
    return (
        times = times[valid_indices],
        gas_masses = gas_masses[valid_indices],
        stellar_masses = stellar_masses[valid_indices],
        mean_densities = mean_densities[valid_indices],
        mean_temperatures = mean_temperatures[valid_indices],
        n_successful = sum(valid_indices),
        n_failed = sum(.!valid_indices)
    )
end

# Run time series analysis
results = memory_efficient_time_series(100:10:500, 10)  # Process 10 snapshots at a time

println(&quot;Time series analysis completed:&quot;)
println(&quot;  Successful snapshots: $(results.n_successful)&quot;)
println(&quot;  Failed snapshots: $(results.n_failed)&quot;)
println(&quot;  Time range: $(minimum(results.times)) - $(maximum(results.times)) Myr&quot;)
println(&quot;  Gas mass range: $(minimum(results.gas_masses)) - $(maximum(results.gas_masses)) Msol&quot;)</code></pre><h3 id="12.4-Time-Series-from-Single-File-JLD2-“Mera-Files”"><a class="docs-heading-anchor" href="#12.4-Time-Series-from-Single-File-JLD2-“Mera-Files”">12.4 Time Series from Single-File JLD2 “Mera Files”</a><a id="12.4-Time-Series-from-Single-File-JLD2-“Mera-Files”-1"></a><a class="docs-heading-anchor-permalink" href="#12.4-Time-Series-from-Single-File-JLD2-“Mera-Files”" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Base.Threads, Mera
using Statistics

&quot;&quot;&quot;
Analyze a time series of single-file JLD2 outputs (&quot;Mera files&quot;) using Mera.loaddata.

Assumptions:
- Files are named like: output_XXXXX.jld2 (standard Mera format)
- Data type is one of :hydro, :particles, :gravity, :clumps

Arguments:
- dir::AbstractString: directory with output_*.jld2 files
- datatype::Symbol: which dataset to load from each file (default :hydro)

Returns NamedTuple with vectors for outputs, files, times (Myr), total_mass, mean_density.
&quot;&quot;&quot;
function analyze_merafiles_timeseries(dir::AbstractString; datatype::Symbol=:hydro)
    # Discover files and parse output numbers
    allfiles = readdir(dir; join=true)
    merafiles = filter(f -&gt; endswith(lowercase(f), &quot;.jld2&quot;) &amp;&amp; occursin(r&quot;output_\d+\.jld2$&quot;, lowercase(basename(f))), allfiles)
    if isempty(merafiles)
        error(&quot;No Mera .jld2 files (output_XXXXX.jld2) found in: $dir&quot;)
    end

    outputs = map(merafiles) do f
        m = match(r&quot;output_(\d+)\.jld2$&quot;, basename(f))
        isnothing(m) &amp;&amp; error(&quot;Unrecognized filename: $(basename(f))&quot;)
        parse(Int, m.captures[1])
    end

    # Sort by output number
    p = sortperm(outputs)
    outputs = outputs[p]
    files = merafiles[p]
    n = length(files)

    # Preallocate results
    times = fill(Float64(NaN), n)
    total_mass = Vector{Float64}(undef, n)
    mean_density = Vector{Float64}(undef, n)

    # Threaded outer loop; internal routines manage their own threading
    @threads for i in 1:n
        out = outputs[i]
        # Load the requested dataset from the Mera file directory
        data_obj = loaddata(out, dir, datatype)

        # Get time directly from the data object (Myr)
        times[i] = gettime(data_obj, :Myr)

        # Compute metrics (adapt as needed for non-hydro datatypes)
        total_mass[i] = msum(data_obj, :Msol)
        mean_density[i] = try
            mean(getvar(data_obj, :rho, :nH))
        catch
            NaN
        end
    end

    return (outputs=outputs, files=files, times=times, total_mass=total_mass, mean_density=mean_density)
end

# Example usage
dir = &quot;/path/to/your/merafiles&quot;  # update this
res = analyze_merafiles_timeseries(dir; datatype=:hydro)

println(&quot;Analyzed $(length(res.files)) Mera JLD2 files&quot;)
finite_times = filter(isfinite, res.times)
println(&quot;Time range (Myr): &quot;, isempty(finite_times) ? (NaN, NaN) : (minimum(finite_times), maximum(finite_times)))
println(&quot;Mass range (Msol): &quot;, (minimum(res.total_mass), maximum(res.total_mass)))
println(&quot;Mean density range (nH): &quot;, (minimum(res.mean_density), maximum(res.mean_density)))</code></pre><p>Notes:</p><ul><li>Uses Mera.loaddata(output, dir, datatype) to read canonical “Mera files.”</li><li>Adjust metrics for non-hydro data (e.g., particles don’t have :rho).</li><li>Tune parallelism by batching outputs if your storage is slow; see Section 3 on I/O contention.</li></ul><h2 id="Summary"><a class="docs-heading-anchor" href="#Summary">Summary</a><a id="Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Summary" title="Permalink"></a></h2><p>This comprehensive guide provides everything needed to harness Julia&#39;s multi-threading capabilities with Mera:</p><p><strong>Key Takeaways:</strong></p><ol><li><strong>Understand resource contention</strong> and use <code>max_threads</code> to control it</li><li><strong>Choose your parallelization level</strong> - outer loops or inner kernels, not both uncontrolled</li><li><strong>Benchmark systematically</strong> to find optimal thread counts for your hardware  </li><li><strong>Monitor GC performance</strong> and tune for large dataset processing</li><li><strong>Transform existing tutorials</strong> with minimal code changes for immediate benefits</li></ol><p><strong>Threading Patterns:</strong></p><ul><li><strong>Outer-loop</strong>: Multiple snapshots/parameters → <code>@threads</code> + <code>max_threads=1</code> inner</li><li><strong>Inner-kernel</strong>: Single large dataset → full internal threading in Mera calls</li><li><strong>Mixed</strong>: Controlled combination with explicit thread budgets</li></ul><p><strong>Best Practices:</strong></p><ul><li>Start Julia with balanced thread pools: <code>julia --threads=auto --gcthreads=auto</code> (uses all available CPU cores)</li><li>Use atomic operations for thread-safe data collection</li><li>Avoid false sharing with proper data structure design</li><li>Profile and benchmark before optimizing</li></ul><p>By following these patterns, you can transform single-threaded analysis scripts into high-throughput, scalable workflows that fully utilize modern multi-core processors—all within pure Julia code, no external dependencies required.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../api/volume_rendering/">« API Reference</a><a class="docs-footer-nextpage" href="../../api/multithreading/">API Reference »</a><div class="flexbox-break"></div><p class="footer-message">© 2025 Manuel Behrendt. Built with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and <a href="https://julialang.org">Julia</a>. </p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Wednesday 10 September 2025 20:34">Wednesday 10 September 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
